diff --git a/Makefile b/Makefile
index 09d790c..cd29e3c 100644
--- a/Makefile
+++ b/Makefile
@@ -24,6 +24,7 @@ OBJS = \
 	sysproc.o\
 	trapasm.o\
 	trap.o\
+	paging.o\
 	uart.o\
 	vectors.o\
 	vm.o\
@@ -77,20 +78,13 @@ LD = $(TOOLPREFIX)ld
 OBJCOPY = $(TOOLPREFIX)objcopy
 OBJDUMP = $(TOOLPREFIX)objdump
 CFLAGS = -fno-pic -static -fno-builtin -fno-strict-aliasing -O2 -Wall -MD -ggdb -m32 -Werror -fno-omit-frame-pointer
+#CFLAGS = -fno-pic -static -fno-builtin -fno-strict-aliasing -fvar-tracking -fvar-tracking-assignments -O0 -g -Wall -MD -gdwarf-2 -m32 -Werror -fno-omit-frame-pointer
 CFLAGS += $(shell $(CC) -fno-stack-protector -E -x c /dev/null >/dev/null 2>&1 && echo -fno-stack-protector)
 ASFLAGS = -m32 -gdwarf-2 -Wa,-divide
 # FreeBSD ld wants ``elf_i386_fbsd''
 LDFLAGS += -m $(shell $(LD) -V | grep elf_i386 2>/dev/null | head -n 1)
 
-# Disable PIE when possible (for Ubuntu 16.10 toolchain)
-ifneq ($(shell $(CC) -dumpspecs 2>/dev/null | grep -e '[^f]no-pie'),)
-CFLAGS += -fno-pie -no-pie
-endif
-ifneq ($(shell $(CC) -dumpspecs 2>/dev/null | grep -e '[^f]nopie'),)
-CFLAGS += -fno-pie -nopie
-endif
-
-xv6.img: bootblock kernel
+xv6.img: bootblock kernel fs.img
 	dd if=/dev/zero of=xv6.img count=10000
 	dd if=bootblock of=xv6.img conv=notrunc
 	dd if=kernel of=xv6.img seek=1 conv=notrunc
@@ -141,7 +135,7 @@ tags: $(OBJS) entryother.S _init
 	etags *.S *.c
 
 vectors.S: vectors.pl
-	./vectors.pl > vectors.S
+	perl vectors.pl > vectors.S
 
 ULIB = ulib.o usys.o printf.o umalloc.o
 
@@ -179,6 +173,9 @@ UPROGS=\
 	_sh\
 	_stressfs\
 	_usertests\
+	_memtest1\
+	_memtest2\
+	_memtest3\
 	_wc\
 	_zombie\
 
@@ -190,8 +187,8 @@ fs.img: mkfs README $(UPROGS)
 clean: 
 	rm -f *.tex *.dvi *.idx *.aux *.log *.ind *.ilg \
 	*.o *.d *.asm *.sym vectors.S bootblock entryother \
-	initcode initcode.out kernel xv6.img fs.img kernelmemfs \
-	xv6memfs.img mkfs .gdbinit \
+	initcode initcode.out kernel xv6.img fs.img kernelmemfs mkfs \
+	.gdbinit \
 	$(UPROGS)
 
 # make a printout
@@ -219,9 +216,10 @@ QEMUGDB = $(shell if $(QEMU) -help | grep -q '^-gdb'; \
 ifndef CPUS
 CPUS := 2
 endif
-QEMUOPTS = -drive file=fs.img,index=1,media=disk,format=raw -drive file=xv6.img,index=0,media=disk,format=raw -smp $(CPUS) -m 512 $(QEMUEXTRA)
+QEMUOPTS = -drive file=fs.img,index=1,media=disk,format=raw -drive file=xv6.img,index=0,media=disk,format=raw -smp $(CPUS) -m 4 $(QEMUEXTRA)
 
 qemu: fs.img xv6.img
+#	$(QEMU) $(QEMUOPTS)
 	$(QEMU) -serial mon:stdio $(QEMUOPTS)
 
 qemu-memfs: xv6memfs.img
@@ -249,7 +247,7 @@ qemu-nox-gdb: fs.img xv6.img .gdbinit
 
 EXTRA=\
 	mkfs.c ulib.c user.h cat.c echo.c forktest.c grep.c kill.c\
-	ln.c ls.c mkdir.c rm.c stressfs.c usertests.c wc.c zombie.c\
+	ln.c ls.c mkdir.c rm.c stressfs.c usertests.c memtest1.c memtest2.c memtest3.c wc.c zombie.c\
 	printf.c umalloc.c\
 	README dot-bochsrc *.pl toc.* runoff runoff1 runoff.list\
 	.gdbinit.tmpl gdbutil\
diff --git a/README b/README
index 923e0a4..f4e4368 100644
--- a/README
+++ b/README
@@ -1,6 +1,47 @@
-NOTE: we have stopped maintaining the x86 version of xv6, and switched
-our efforts to the RISC-V version
-(https://github.com/mit-pdos/xv6-riscv.git)
+# xv7 
+Implementation of Demand Paging and Swapping in xv6 with **all test cases passing**
+
+### Usage
+
+You can boot xv7 OS in qemu emulator:
+```
+sudo apt-get install qemu
+make qemu
+```
+To test demand paging :
+```
+memtest1
+```
+To test swapping and fork :
+```
+memtest2
+```
+#### Important :warning:
+> Replace README.MD with this [README](https://github.com/mit-pdos/xv6-public/blob/master/README) file, otherwise it won't run.
+
+### Changed files 
+
+1. **bio.c** *(for swapping)*
+    * write_page_to_disk()
+    * read_page_from_disk()
+2. **fs.c** *(for swapping)*
+    * balloc_page()
+    * bfree_page()
+3. **paging.c** *(for demand paging)*
+    * map_address()
+    * swap_page()
+    * swap_page_from_pte()
+4. **vm.c** *(for demand paging)*
+    * select_a_victim()
+    * clearaccessbit()
+    * getswappedblk()
+
+And a few minor changes at different places, all changes begin with the following comment:
+> \*\*\*\**\*\*\*\*\*\*\*xv7\*\*\*\*\*\*\*\*\*\*\*\*\*
+
+
+
+### About xv6  
 
 xv6 is a re-implementation of Dennis Ritchie's and Ken Thompson's Unix
 Version 6 (v6).  xv6 loosely follows the structure and style of v6,
@@ -10,7 +51,7 @@ ACKNOWLEDGMENTS
 
 xv6 is inspired by John Lions's Commentary on UNIX 6th Edition (Peer
 to Peer Communications; ISBN: 1-57398-013-7; 1st edition (June 14,
-2000)). See also https://pdos.csail.mit.edu/6.828/, which
+2000)). See also http://pdos.csail.mit.edu/6.828/2016/xv6.html, which
 provides pointers to on-line resources for v6.
 
 xv6 borrows code from the following sources:
@@ -24,28 +65,30 @@ locking), Cliff Frey (MP), Xiao Yu (MP), Nickolai Zeldovich, and Austin
 Clements.
 
 We are also grateful for the bug reports and patches contributed by Silas
-Boyd-Wickizer, Anton Burtsev, Cody Cutler, Mike CAT, Tej Chajed, eyalz800,
-Nelson Elhage, Saar Ettinger, Alice Ferrazzi, Nathaniel Filardo, Peter
-Froehlich, Yakir Goaron,Shivam Handa, Bryan Henry, Jim Huang, Alexander
-Kapshuk, Anders Kaseorg, kehao95, Wolfgang Keller, Eddie Kohler, Austin
-Liew, Imbar Marinescu, Yandong Mao, Matan Shabtay, Hitoshi Mitake, Carmi
-Merimovich, Mark Morrissey, mtasm, Joel Nider, Greg Price, Ayan Shafqat,
-Eldar Sehayek, Yongming Shen, Cam Tenny, tyfkda, Rafael Ubal, Warren
-Toomey, Stephen Tu, Pablo Ventura, Xi Wang, Keiichi Watanabe, Nicolas
-Wolovick, wxdao, Grant Wu, Jindong Zhang, Icenowy Zheng, and Zou Chang Wei.
+Boyd-Wickizer, Anton Burtsev, Cody Cutler, Mike CAT, Tej Chajed, Nelson Elhage,
+Saar Ettinger, Alice Ferrazzi, Nathaniel Filardo, Peter Froehlich, Yakir Goaron,
+Shivam Handa, Bryan Henry, Jim Huang, Alexander Kapshuk, Anders Kaseorg,
+kehao95, Wolfgang Keller, Eddie Kohler, Austin Liew, Imbar Marinescu, Yandong
+Mao, Hitoshi Mitake, Carmi Merimovich, Joel Nider, Greg Price, Ayan Shafqat,
+Eldar Sehayek, Yongming Shen, Cam Tenny, Rafael Ubal, Warren Toomey, Stephen Tu,
+Pablo Ventura, Xi Wang, Keiichi Watanabe, Nicolas Wolovick, Grant Wu, Jindong
+Zhang, Icenowy Zheng, and Zou Chang Wei.
 
 The code in the files that constitute xv6 is
-Copyright 2006-2018 Frans Kaashoek, Robert Morris, and Russ Cox.
+Copyright 2006-2016 Frans Kaashoek, Robert Morris, and Russ Cox.
 
 ERROR REPORTS
 
-We don't process error reports (see note on top of this file).
+Please send errors and suggestions to Frans Kaashoek and Robert Morris
+(kaashoek,rtm@mit.edu). The main purpose of xv6 is as a teaching
+operating system for MIT's 6.828, so we are more interested in
+simplifications and clarifications than new features.
 
 BUILDING AND RUNNING XV6
 
 To build xv6 on an x86 ELF machine (like Linux or FreeBSD), run
 "make". On non-x86 or non-ELF machines (like OS X, even on x86), you
 will need to install a cross-compiler gcc suite capable of producing
-x86 ELF binaries (see https://pdos.csail.mit.edu/6.828/).
+x86 ELF binaries. See http://pdos.csail.mit.edu/6.828/2016/tools.html.
 Then run "make TOOLPREFIX=i386-jos-elf-". Now install the QEMU PC
-simulator and run "make qemu".
\ No newline at end of file
+simulator and run "make qemu".
diff --git a/asm.h b/asm.h
index b8a7353..68210d7 100644
--- a/asm.h
+++ b/asm.h
@@ -14,5 +14,8 @@
                 (0xC0 | (((lim) >> 28) & 0xf)), (((base) >> 24) & 0xff)
 
 #define STA_X     0x8       // Executable segment
+#define STA_E     0x4       // Expand down (non-executable segments)
+#define STA_C     0x4       // Conforming code segment (executable only)
 #define STA_W     0x2       // Writeable (non-executable segments)
 #define STA_R     0x2       // Readable (executable segments)
+#define STA_A     0x1       // Accessed
diff --git a/bio.c b/bio.c
index a45ff3e..264ffa2 100644
--- a/bio.c
+++ b/bio.c
@@ -29,9 +29,6 @@
 struct {
   struct spinlock lock;
   struct buf buf[NBUF];
-
-  // Linked list of all buffers, through prev/next.
-  // head.next is most recently used.
   struct buf head;
 } bcache;
 
@@ -39,10 +36,8 @@ void
 binit(void)
 {
   struct buf *b;
-
   initlock(&bcache.lock, "bcache");
 
-//PAGEBREAK!
   // Create linked list of buffers
   bcache.head.prev = &bcache.head;
   bcache.head.next = &bcache.head;
@@ -62,7 +57,6 @@ static struct buf*
 bget(uint dev, uint blockno)
 {
   struct buf *b;
-
   acquire(&bcache.lock);
 
   // Is the block already cached?
@@ -92,6 +86,46 @@ bget(uint dev, uint blockno)
   panic("bget: no buffers");
 }
 
+// Write 4096 bytes pg to the eight consecutive starting at blk. 
+void
+write_page_to_disk(uint dev, char *pg, uint blk)
+{
+  struct buf* buffer;
+  int blockno = 0;
+  int ithPartOfPage = 0;        // which part of page (out of 8) is to be written to disk
+  for(int i=0;i<8;i++)
+  {
+    // for atomicity, the block must be written to the disk
+    ithPartOfPage = i*512;
+    blockno = blk+i;
+    buffer = bget(ROOTDEV,blockno);
+    /*
+      Writing physical page to disk by dividing it into 8 pieces (4096 bytes/8 = 512 bytes = 1 block)
+      As one page requires 8 disk blocks
+    */
+    memmove(buffer->data,pg+ithPartOfPage,512);   // write 512 bytes to the block
+    bwrite(buffer);
+    brelse(buffer);                               //release lock
+  }
+}
+
+// Read 4096 bytes from the eight consecutive starting at blk into pg.
+void
+read_page_from_disk(uint dev, char *pg, uint blk)
+{
+  struct buf* buffer;
+  int blockno=0;
+  int ithPartOfPage=0;
+  for(int i=0;i<8;i++){
+    ithPartOfPage=i*512;
+    blockno=blk+i;
+    buffer=bread(ROOTDEV,blockno);                // if present in buffer, returns from buffer else from disk
+    memmove(pg+ithPartOfPage, buffer->data,512);  // write to pg from buffer
+    brelse(buffer);                               // release lock
+  }
+
+}
+
 // Return a locked buf with the contents of the indicated block.
 struct buf*
 bread(uint dev, uint blockno)
@@ -105,7 +139,7 @@ bread(uint dev, uint blockno)
   return b;
 }
 
-// Write b's contents to disk.  Must be locked.
+// Write b's contents to disk. Must be locked.
 void
 bwrite(struct buf *b)
 {
@@ -128,7 +162,6 @@ brelse(struct buf *b)
   acquire(&bcache.lock);
   b->refcnt--;
   if (b->refcnt == 0) {
-    // no one is waiting for it.
     b->next->prev = b->prev;
     b->prev->next = b->next;
     b->next = bcache.head.next;
@@ -136,9 +169,6 @@ brelse(struct buf *b)
     bcache.head.next->prev = b;
     bcache.head.next = b;
   }
-  
+
   release(&bcache.lock);
 }
-//PAGEBREAK!
-// Blank page.
-
diff --git a/buf.h b/buf.h
index 3266495..a5bc09b 100644
--- a/buf.h
+++ b/buf.h
@@ -9,6 +9,9 @@ struct buf {
   struct buf *qnext; // disk queue
   uchar data[BSIZE];
 };
+
+//*** change ****
+#define B_BUSY  0x1  // buffer is locked by some process
 #define B_VALID 0x2  // buffer has been read from disk
 #define B_DIRTY 0x4  // buffer needs to be written to disk
 
diff --git a/defs.h b/defs.h
index 82fb982..5f3db03 100644
--- a/defs.h
+++ b/defs.h
@@ -52,7 +52,10 @@ struct inode*   nameiparent(char*, char*);
 int             readi(struct inode*, char*, uint, uint);
 void            stati(struct inode*, struct stat*);
 int             writei(struct inode*, char*, uint, uint);
-
+int				createSwapFile(struct proc* p);
+int				readFromSwapFile(struct proc * p, char* buffer, uint placeOnFile, uint size);
+int				writeToSwapFile(struct proc* p, char* buffer, uint placeOnFile, uint size);
+int				removeSwapFile(struct proc* p);
 // ide.c
 void            ideinit(void);
 void            ideintr(void);
@@ -74,6 +77,7 @@ void            kbdintr(void);
 
 // lapic.c
 void            cmostime(struct rtcdate *r);
+//int             cpunum(void);
 int             lapicid(void);
 extern volatile uint*    lapic;
 void            lapiceoi(void);
@@ -89,7 +93,9 @@ void            end_op();
 
 // mp.c
 extern int      ismp;
+int             mpbcpu(void);
 void            mpinit(void);
+void            mpstartthem(void);
 
 // picirq.c
 void            picenable(int);
@@ -104,6 +110,8 @@ int             pipewrite(struct pipe*, char*, int);
 //PAGEBREAK: 16
 // proc.c
 int             cpuid(void);
+void			NFUupdate();
+struct proc*    copyproc(struct proc*);
 void            exit(void);
 int             fork(void);
 int             growproc(int);
@@ -124,6 +132,10 @@ void            yield(void);
 // swtch.S
 void            swtch(struct context**, struct context*);
 
+// sysfile
+struct inode*	create(char *path, short type, short major, short minor);
+int				isdirempty(struct inode *dp);
+
 // spinlock.c
 void            acquire(struct spinlock*);
 void            getcallerpcs(void*, uint*);
@@ -133,12 +145,14 @@ void            release(struct spinlock*);
 void            pushcli(void);
 void            popcli(void);
 
+
 // sleeplock.c
 void            acquiresleep(struct sleeplock*);
 void            releasesleep(struct sleeplock*);
 int             holdingsleep(struct sleeplock*);
 void            initsleeplock(struct sleeplock*, char*);
 
+
 // string.c
 int             memcmp(const void*, const void*, uint);
 void*           memmove(void*, const void*, uint);
@@ -147,6 +161,7 @@ char*           safestrcpy(char*, const char*, int);
 int             strlen(const char*);
 int             strncmp(const char*, const char*, uint);
 char*           strncpy(char*, const char*, int);
+int             strcmp(const char *, const char *);
 
 // syscall.c
 int             argint(int, int*);
@@ -171,8 +186,10 @@ void            uartintr(void);
 void            uartputc(int);
 
 // vm.c
+void 			checkProcAccBit();
 void            seginit(void);
 void            kvmalloc(void);
+void            vmenable(void);
 pde_t*          setupkvm(void);
 char*           uva2ka(pde_t*, char*);
 int             allocuvm(pde_t*, uint, uint);
@@ -185,6 +202,7 @@ void            switchuvm(struct proc*);
 void            switchkvm(void);
 int             copyout(pde_t*, uint, void*, uint);
 void            clearpteu(pde_t *pgdir, char *uva);
+void            swapPages(uint);
 
 // number of elements in fixed-size array
 #define NELEM(x) (sizeof(x)/sizeof((x)[0]))
diff --git a/file.c b/file.c
index 24b32c2..9089773 100644
--- a/file.c
+++ b/file.c
@@ -1,7 +1,3 @@
-//
-// File descriptors
-//
-
 #include "types.h"
 #include "defs.h"
 #include "param.h"
diff --git a/file.h b/file.h
index 0990c82..bbdc07d 100644
--- a/file.h
+++ b/file.h
@@ -8,7 +8,6 @@ struct file {
   uint off;
 };
 
-
 // in-memory copy of an inode
 struct inode {
   uint dev;           // Device number
@@ -16,7 +15,8 @@ struct inode {
   int ref;            // Reference count
   struct sleeplock lock; // protects everything below here
   int valid;          // inode has been read from disk?
-
+  // **** changes ****
+  int flags;          // I_BUSY, I_VALID
   short type;         // copy of disk inode
   short major;
   short minor;
@@ -25,6 +25,10 @@ struct inode {
   uint addrs[NDIRECT+1];
 };
 
+// Changes 
+#define I_BUSY 0x1	
+#define I_VALID 0x2	
+
 // table mapping major device number to
 // device functions
 struct devsw {
@@ -33,5 +37,4 @@ struct devsw {
 };
 
 extern struct devsw devsw[];
-
-#define CONSOLE 1
+#define CONSOLE 1
\ No newline at end of file
diff --git a/forktest.c b/forktest.c
index 8bc984d..73f2fe8 100644
--- a/forktest.c
+++ b/forktest.c
@@ -8,7 +8,7 @@
 #define N  1000
 
 void
-printf(int fd, const char *s, ...)
+printf(int fd, char *s, ...)
 {
   write(fd, s, strlen(s));
 }
diff --git a/fs.c b/fs.c
index f77275f..cf0ecf3 100644
--- a/fs.c
+++ b/fs.c
@@ -1,14 +1,3 @@
-// File system implementation.  Five layers:
-//   + Blocks: allocator for raw disk blocks.
-//   + Log: crash recovery for multi-step updates.
-//   + Files: inode allocator, reading, writing, metadata.
-//   + Directories: inode with special contents (list of other inodes!)
-//   + Names: paths like /usr/rtm/xv6/fs.c for convenient naming.
-//
-// This file contains the low-level file system manipulation
-// routines.  The (higher-level) system call implementations
-// are in sysfile.c.
-
 #include "types.h"
 #include "defs.h"
 #include "param.h"
@@ -23,16 +12,16 @@
 
 #define min(a, b) ((a) < (b) ? (a) : (b))
 static void itrunc(struct inode*);
-// there should be one superblock per disk device, but we run with
-// only one device
-struct superblock sb; 
+static void bfree(int dev, uint b);
+
+struct superblock sb;
+int numallocblocks = 0;
 
 // Read the super block.
-void
+void 
 readsb(int dev, struct superblock *sb)
 {
   struct buf *bp;
-
   bp = bread(dev, 1);
   memmove(sb, bp->data, sizeof(*sb));
   brelse(bp);
@@ -43,32 +32,30 @@ static void
 bzero(int dev, int bno)
 {
   struct buf *bp;
-
   bp = bread(dev, bno);
   memset(bp->data, 0, BSIZE);
   log_write(bp);
   brelse(bp);
 }
 
-// Blocks.
-
 // Allocate a zeroed disk block.
 static uint
 balloc(uint dev)
 {
   int b, bi, m;
   struct buf *bp;
-
   bp = 0;
   for(b = 0; b < sb.size; b += BPB){
     bp = bread(dev, BBLOCK(b, sb));
     for(bi = 0; bi < BPB && b + bi < sb.size; bi++){
       m = 1 << (bi % 8);
       if((bp->data[bi/8] & m) == 0){  // Is block free?
-        bp->data[bi/8] |= m;  // Mark block in use.
+        begin_op();
+        bp->data[bi/8] |= m;          // Mark block in use.
         log_write(bp);
         brelse(bp);
         bzero(dev, b + bi);
+        end_op();
         return b + bi;
       }
     }
@@ -77,92 +64,56 @@ balloc(uint dev)
   panic("balloc: out of blocks");
 }
 
-// Free a disk block.
+uint
+balloc_page(uint dev)
+{
+  uint allocatedBlocks[100000];
+  int indexNCB = -1;                        // pointer for above array, keeps track till where it is filled
+  for(int i = 0;i < 8; i++)
+  {
+      indexNCB++;
+      allocatedBlocks[indexNCB] = balloc(dev);
+      if(i > 0){
+          if((allocatedBlocks[indexNCB]-allocatedBlocks[indexNCB-1])!=1) {
+              i = 0;                        // start allocating blocks again
+          }
+      }
+    }
+    for(int i = 0;i <= indexNCB-8; i++){
+      bfree(ROOTDEV,allocatedBlocks[i]);    // free unnecesarily allocated blocks
+    }
+    numallocblocks += 1;      
+	  return allocatedBlocks[indexNCB-7];    // return last 8 blocks (address of 1st block among them)
+}
+
+// Free disk blocks allocated using balloc_page.
+void
+bfree_page(int dev, uint b)
+{ 
+  for(uint i = 0;i < 8; i++){
+    bfree(ROOTDEV,b+i);
+  }
+  numallocblocks -= 1;      
+}
+
+// Free a disk block
 static void
 bfree(int dev, uint b)
 {
   struct buf *bp;
   int bi, m;
 
+  readsb(dev, &sb);
   bp = bread(dev, BBLOCK(b, sb));
   bi = b % BPB;
   m = 1 << (bi % 8);
   if((bp->data[bi/8] & m) == 0)
     panic("freeing free block");
   bp->data[bi/8] &= ~m;
-  log_write(bp);
+  bwrite(bp);
   brelse(bp);
 }
 
-// Inodes.
-//
-// An inode describes a single unnamed file.
-// The inode disk structure holds metadata: the file's type,
-// its size, the number of links referring to it, and the
-// list of blocks holding the file's content.
-//
-// The inodes are laid out sequentially on disk at
-// sb.startinode. Each inode has a number, indicating its
-// position on the disk.
-//
-// The kernel keeps a cache of in-use inodes in memory
-// to provide a place for synchronizing access
-// to inodes used by multiple processes. The cached
-// inodes include book-keeping information that is
-// not stored on disk: ip->ref and ip->valid.
-//
-// An inode and its in-memory representation go through a
-// sequence of states before they can be used by the
-// rest of the file system code.
-//
-// * Allocation: an inode is allocated if its type (on disk)
-//   is non-zero. ialloc() allocates, and iput() frees if
-//   the reference and link counts have fallen to zero.
-//
-// * Referencing in cache: an entry in the inode cache
-//   is free if ip->ref is zero. Otherwise ip->ref tracks
-//   the number of in-memory pointers to the entry (open
-//   files and current directories). iget() finds or
-//   creates a cache entry and increments its ref; iput()
-//   decrements ref.
-//
-// * Valid: the information (type, size, &c) in an inode
-//   cache entry is only correct when ip->valid is 1.
-//   ilock() reads the inode from
-//   the disk and sets ip->valid, while iput() clears
-//   ip->valid if ip->ref has fallen to zero.
-//
-// * Locked: file system code may only examine and modify
-//   the information in an inode and its content if it
-//   has first locked the inode.
-//
-// Thus a typical sequence is:
-//   ip = iget(dev, inum)
-//   ilock(ip)
-//   ... examine and modify ip->xxx ...
-//   iunlock(ip)
-//   iput(ip)
-//
-// ilock() is separate from iget() so that system calls can
-// get a long-term reference to an inode (as for an open file)
-// and only lock it for short periods (e.g., in read()).
-// The separation also helps avoid deadlock and races during
-// pathname lookup. iget() increments ip->ref so that the inode
-// stays cached and pointers to it remain valid.
-//
-// Many internal file system functions expect the caller to
-// have locked the inodes involved; this lets callers create
-// multi-step atomic operations.
-//
-// The icache.lock spin-lock protects the allocation of icache
-// entries. Since ip->ref indicates whether an entry is free,
-// and ip->dev and ip->inum indicate which i-node an entry
-// holds, one must hold icache.lock while using any of those fields.
-//
-// An ip->lock sleep-lock protects all ip-> fields other than ref,
-// dev, and inum.  One must hold ip->lock in order to
-// read or write that inode's ip->valid, ip->size, ip->type, &c.
-
 struct {
   struct spinlock lock;
   struct inode inode[NINODE];
@@ -172,25 +123,20 @@ void
 iinit(int dev)
 {
   int i = 0;
-  
+
   initlock(&icache.lock, "icache");
   for(i = 0; i < NINODE; i++) {
     initsleeplock(&icache.inode[i].lock, "inode");
   }
-
   readsb(dev, &sb);
   cprintf("sb: size %d nblocks %d ninodes %d nlog %d logstart %d\
- inodestart %d bmap start %d\n", sb.size, sb.nblocks,
+  inodestart %d bmap start %d\n", sb.size, sb.nblocks,
           sb.ninodes, sb.nlog, sb.logstart, sb.inodestart,
           sb.bmapstart);
 }
 
 static struct inode* iget(uint dev, uint inum);
 
-//PAGEBREAK!
-// Allocate an inode on device dev.
-// Mark it as allocated by  giving it type type.
-// Returns an unlocked but allocated and referenced inode.
 struct inode*
 ialloc(uint dev, short type)
 {
@@ -213,10 +159,6 @@ ialloc(uint dev, short type)
   panic("ialloc: no inodes");
 }
 
-// Copy a modified in-memory inode to disk.
-// Must be called after every change to an ip->xxx field
-// that lives on disk, since i-node cache is write-through.
-// Caller must hold ip->lock.
 void
 iupdate(struct inode *ip)
 {
@@ -235,9 +177,6 @@ iupdate(struct inode *ip)
   brelse(bp);
 }
 
-// Find the inode with number inum on device dev
-// and return the in-memory copy. Does not lock
-// the inode and does not read it from disk.
 static struct inode*
 iget(uint dev, uint inum)
 {
@@ -245,7 +184,6 @@ iget(uint dev, uint inum)
 
   acquire(&icache.lock);
 
-  // Is the inode already cached?
   empty = 0;
   for(ip = &icache.inode[0]; ip < &icache.inode[NINODE]; ip++){
     if(ip->ref > 0 && ip->dev == dev && ip->inum == inum){
@@ -257,7 +195,6 @@ iget(uint dev, uint inum)
       empty = ip;
   }
 
-  // Recycle an inode cache entry.
   if(empty == 0)
     panic("iget: no inodes");
 
@@ -267,12 +204,9 @@ iget(uint dev, uint inum)
   ip->ref = 1;
   ip->valid = 0;
   release(&icache.lock);
-
   return ip;
 }
 
-// Increment reference count for ip.
-// Returns ip to enable ip = idup(ip1) idiom.
 struct inode*
 idup(struct inode *ip)
 {
@@ -282,8 +216,6 @@ idup(struct inode *ip)
   return ip;
 }
 
-// Lock the given inode.
-// Reads the inode from disk if necessary.
 void
 ilock(struct inode *ip)
 {
@@ -311,7 +243,6 @@ ilock(struct inode *ip)
   }
 }
 
-// Unlock the given inode.
 void
 iunlock(struct inode *ip)
 {
@@ -321,13 +252,6 @@ iunlock(struct inode *ip)
   releasesleep(&ip->lock);
 }
 
-// Drop a reference to an in-memory inode.
-// If that was the last reference, the inode cache entry can
-// be recycled.
-// If that was the last reference and the inode has no links
-// to it, free the inode (and its content) on disk.
-// All calls to iput() must be inside a transaction in
-// case it has to free the inode.
 void
 iput(struct inode *ip)
 {
@@ -337,7 +261,6 @@ iput(struct inode *ip)
     int r = ip->ref;
     release(&icache.lock);
     if(r == 1){
-      // inode has no links and no other references: truncate and free.
       itrunc(ip);
       ip->type = 0;
       iupdate(ip);
@@ -351,7 +274,6 @@ iput(struct inode *ip)
   release(&icache.lock);
 }
 
-// Common idiom: unlock, then put.
 void
 iunlockput(struct inode *ip)
 {
@@ -359,16 +281,6 @@ iunlockput(struct inode *ip)
   iput(ip);
 }
 
-//PAGEBREAK!
-// Inode content
-//
-// The content (data) associated with each inode is stored
-// in blocks on the disk. The first NDIRECT block numbers
-// are listed in ip->addrs[].  The next NINDIRECT blocks are
-// listed in block ip->addrs[NDIRECT].
-
-// Return the disk block address of the nth block in inode ip.
-// If there is no such block, bmap allocates one.
 static uint
 bmap(struct inode *ip, uint bn)
 {
@@ -399,11 +311,6 @@ bmap(struct inode *ip, uint bn)
   panic("bmap: out of range");
 }
 
-// Truncate inode (discard contents).
-// Only called when the inode has no links
-// to it (no directory entries referring to it)
-// and has no in-memory reference to it (is
-// not an open file or current directory).
 static void
 itrunc(struct inode *ip)
 {
@@ -434,8 +341,6 @@ itrunc(struct inode *ip)
   iupdate(ip);
 }
 
-// Copy stat information from inode.
-// Caller must hold ip->lock.
 void
 stati(struct inode *ip, struct stat *st)
 {
@@ -446,9 +351,6 @@ stati(struct inode *ip, struct stat *st)
   st->size = ip->size;
 }
 
-//PAGEBREAK!
-// Read data from inode.
-// Caller must hold ip->lock.
 int
 readi(struct inode *ip, char *dst, uint off, uint n)
 {
@@ -475,9 +377,6 @@ readi(struct inode *ip, char *dst, uint off, uint n)
   return n;
 }
 
-// PAGEBREAK!
-// Write data to inode.
-// Caller must hold ip->lock.
 int
 writei(struct inode *ip, char *src, uint off, uint n)
 {
@@ -510,12 +409,8 @@ writei(struct inode *ip, char *src, uint off, uint n)
   return n;
 }
 
-//PAGEBREAK!
-// Directories
-
 int
-namecmp(const char *s, const char *t)
-{
+namecmp(const char *s, const char *t) {
   return strncmp(s, t, DIRSIZ);
 }
 
@@ -577,21 +472,6 @@ dirlink(struct inode *dp, char *name, uint inum)
   return 0;
 }
 
-//PAGEBREAK!
-// Paths
-
-// Copy the next path element from path into name.
-// Return a pointer to the element following the copied one.
-// The returned path has no leading slashes,
-// so the caller can check *path=='\0' to see if the name is the last one.
-// If no name to remove, return 0.
-//
-// Examples:
-//   skipelem("a/bb/c", name) = "bb/c", setting name = "a"
-//   skipelem("///a//bb", name) = "bb", setting name = "a"
-//   skipelem("a", name) = "", setting name = "a"
-//   skipelem("", name) = skipelem("////", name) = 0
-//
 static char*
 skipelem(char *path, char *name)
 {
@@ -617,10 +497,6 @@ skipelem(char *path, char *name)
   return path;
 }
 
-// Look up and return the inode for a path name.
-// If parent != 0, return the inode for the parent and copy the final
-// path element into name, which must have room for DIRSIZ bytes.
-// Must be called inside a transaction since it calls iput().
 static struct inode*
 namex(char *path, int nameiparent, char *name)
 {
@@ -668,3 +544,142 @@ nameiparent(char *path, char *name)
 {
   return namex(path, 1, name);
 }
+
+
+#include "fcntl.h"
+#define DIGITS 14
+
+char* 
+itoa(int i, char b[])
+{
+    char const digit[] = "0123456789";
+    char* p = b;
+    if(i < 0){
+        *p++ = '-';
+        i *= -1;
+    }
+    int shifter = i;
+    do {                          // Move to where representation ends
+        ++p;
+        shifter = shifter/10;
+    } 
+    while(shifter);
+    *p = '\0';
+    do {                          // Move back, inserting digits as u go
+        *--p = digit[i%10];
+        i = i/10;
+    } 
+    while(i);
+    return b;
+}
+
+// remove swap file of proc p
+int
+removeSwapFile(struct proc* p)
+{
+	//path of proccess
+	char path[DIGITS];
+	memmove(path,"/.swap", 6);
+	itoa(p->pid, path+ 6);
+
+	struct inode *ip, *dp;
+	struct dirent de;
+	char name[DIRSIZ];
+	uint off;
+
+  if(0 == p->swapFile) {
+    return -1;
+  }
+  fileclose(p->swapFile);
+
+	begin_op();
+	if((dp = nameiparent(path, name)) == 0)
+	{
+		end_op();
+		return -1;
+	}
+
+	ilock(dp);
+
+	  // Cannot unlink "." or "..".
+	if(namecmp(name, ".") == 0 || namecmp(name, "..") == 0)
+	   goto bad;
+
+	if((ip = dirlookup(dp, name, &off)) == 0)
+		goto bad;
+	ilock(ip);
+
+	if(ip->nlink < 1)
+		panic("unlink: nlink < 1");
+	if(ip->type == T_DIR && !isdirempty(ip)){
+		iunlockput(ip);
+		goto bad;
+	}
+
+	memset(&de, 0, sizeof(de));
+	if(writei(dp, (char*)&de, off, sizeof(de)) != sizeof(de))
+		panic("unlink: writei");
+	if(ip->type == T_DIR){
+		dp->nlink--;
+		iupdate(dp);
+	}
+	iunlockput(dp);
+
+	ip->nlink--;
+	iupdate(ip);
+	iunlockput(ip);
+
+	end_op();
+
+	return 0;
+
+	bad:
+		iunlockput(dp);
+		end_op();
+		return -1;
+}
+
+
+// return 0 on success
+int
+createSwapFile(struct proc* p)
+{
+
+	char path[DIGITS];
+	memmove(path,"/.swap", 6);
+	itoa(p->pid, path+ 6);
+
+    begin_op();
+    struct inode * in = create(path, T_FILE, 0, 0);
+	iunlock(in);
+
+	p->swapFile = filealloc();
+	if (p->swapFile == 0)
+		panic("no slot for files on /store");
+
+	p->swapFile->ip = in;
+	p->swapFile->type = FD_INODE;
+	p->swapFile->off = 0;
+	p->swapFile->readable = O_WRONLY;
+	p->swapFile->writable = O_RDWR;
+    end_op();
+
+    return 0;
+}
+
+// return as sys_write (-1 when error)
+int
+writeToSwapFile(struct proc * p, char* buffer, uint placeOnFile, uint size)
+{
+	p->swapFile->off = placeOnFile;
+	return filewrite(p->swapFile, buffer, size);
+
+}
+
+// return as sys_read (-1 when error)
+int
+readFromSwapFile(struct proc * p, char* buffer, uint placeOnFile, uint size)
+{
+	p->swapFile->off = placeOnFile;
+	return fileread(p->swapFile, buffer,  size);
+}
diff --git a/fs.h b/fs.h
index 3214f1d..cd9bef4 100644
--- a/fs.h
+++ b/fs.h
@@ -55,3 +55,8 @@ struct dirent {
   char name[DIRSIZ];
 };
 
+
+uint balloc_page(uint dev);
+void bfree_page(int dev, uint b);
+void write_page_to_disk(uint dev, char *pg, uint blk);
+void read_page_from_disk(uint dev, char *pg, uint blk);
diff --git a/kalloc.c b/kalloc.c
index 14cd4f4..677d9e5 100644
--- a/kalloc.c
+++ b/kalloc.c
@@ -8,10 +8,12 @@
 #include "memlayout.h"
 #include "mmu.h"
 #include "spinlock.h"
+#include "kalloc.h"
+
+struct physPagesCounts physPagesCounts;
 
 void freerange(void *vstart, void *vend);
 extern char end[]; // first address after kernel loaded from ELF file
-                   // defined by the kernel linker script in kernel.ld
 
 struct run {
   struct run *next;
@@ -34,12 +36,20 @@ kinit1(void *vstart, void *vend)
   initlock(&kmem.lock, "kmem");
   kmem.use_lock = 0;
   freerange(vstart, vend);
+
+  // physPagesCounts is a struct defined in kalloc.h to hold info needed to cumpute percent of free physcal pages
+  // all physical pages allocated to the kernel's allocator's "freelist" are allocated in kinit1 & kinit2
+  // here we update the # of pages inserted to free list in kinit1
+  physPagesCounts.initPagesNo = (PGROUNDDOWN((uint)vend) - PGROUNDUP((uint)vstart)) / PGSIZE;
+  cprintf("physPagesCounts->initPagesNo = %d\n", physPagesCounts.initPagesNo );
 }
 
 void
 kinit2(void *vstart, void *vend)
 {
   freerange(vstart, vend);
+  // update the # of pages inserted to free list in kinit2
+  physPagesCounts.initPagesNo += (PGROUNDDOWN((uint)vend) - PGROUNDUP((uint)vstart)) / PGSIZE;
   kmem.use_lock = 1;
 }
 
@@ -51,6 +61,7 @@ freerange(void *vstart, void *vend)
   for(; p + PGSIZE <= (char*)vend; p += PGSIZE)
     kfree(p);
 }
+
 //PAGEBREAK: 21
 // Free the page of physical memory pointed at by v,
 // which normally should have been returned by a
@@ -72,6 +83,7 @@ kfree(char *v)
   r = (struct run*)v;
   r->next = kmem.freelist;
   kmem.freelist = r;
+  physPagesCounts.currentFreePagesNo++;
   if(kmem.use_lock)
     release(&kmem.lock);
 }
@@ -87,10 +99,11 @@ kalloc(void)
   if(kmem.use_lock)
     acquire(&kmem.lock);
   r = kmem.freelist;
-  if(r)
+  if(r){
     kmem.freelist = r->next;
+    physPagesCounts.currentFreePagesNo--;
+  }
   if(kmem.use_lock)
     release(&kmem.lock);
   return (char*)r;
 }
-
diff --git a/kalloc.h b/kalloc.h
new file mode 100644
index 0000000..9477fda
--- /dev/null
+++ b/kalloc.h
@@ -0,0 +1,7 @@
+// struct for keeping track of the percent of free physical pages
+struct physPagesCounts{
+  uint initPagesNo;
+  uint currentFreePagesNo;
+};
+
+extern struct physPagesCounts physPagesCounts;
diff --git a/kernel.ld b/kernel.ld
index 4e12e14..e24c860 100644
--- a/kernel.ld
+++ b/kernel.ld
@@ -26,12 +26,16 @@ SECTIONS
 		PROVIDE(__STAB_BEGIN__ = .);
 		*(.stab);
 		PROVIDE(__STAB_END__ = .);
+		BYTE(0)		/* Force the linker to allocate space
+				   for this section */
 	}
 
 	.stabstr : {
 		PROVIDE(__STABSTR_BEGIN__ = .);
 		*(.stabstr);
 		PROVIDE(__STABSTR_END__ = .);
+		BYTE(0)		/* Force the linker to allocate space
+				   for this section */
 	}
 
 	/* Adjust the address for the data segment to the next page */
diff --git a/lapic.c b/lapic.c
index b22bbd7..1c72e8d 100644
--- a/lapic.c
+++ b/lapic.c
@@ -99,7 +99,21 @@ lapicinit(void)
 
 int
 lapicid(void)
-{
+{ 
+  
+  // Cannot call cpu when interrupts are enabled:
+  // result not guaranteed to last long enough to be used!
+  // Would prefer to panic but even printing is chancy here:
+  // almost everything, including cprintf and panic, calls cpu,
+  // often indirectly through acquire and release.
+  if(readeflags()&FL_IF){
+    static int n;
+    if(n++ == 0)
+      cprintf("cpu called from %x with interrupts enabled\n",
+        __builtin_return_address(0));
+  }
+  
+  
   if (!lapic)
     return 0;
   return lapic[ID] >> 24;
@@ -171,8 +185,7 @@ lapicstartap(uchar apicid, uint addr)
 #define MONTH   0x08
 #define YEAR    0x09
 
-static uint
-cmos_read(uint reg)
+static uint cmos_read(uint reg)
 {
   outb(CMOS_PORT,  reg);
   microdelay(200);
@@ -180,8 +193,7 @@ cmos_read(uint reg)
   return inb(CMOS_RETURN);
 }
 
-static void
-fill_rtcdate(struct rtcdate *r)
+static void fill_rtcdate(struct rtcdate *r)
 {
   r->second = cmos_read(SECS);
   r->minute = cmos_read(MINS);
@@ -192,8 +204,7 @@ fill_rtcdate(struct rtcdate *r)
 }
 
 // qemu seems to use 24-hour GWT and the values are BCD encoded
-void
-cmostime(struct rtcdate *r)
+void cmostime(struct rtcdate *r)
 {
   struct rtcdate t1, t2;
   int sb, bcd;
diff --git a/main.c b/main.c
index 9924e64..f4040c3 100644
--- a/main.c
+++ b/main.c
@@ -34,6 +34,8 @@ main(void)
   startothers();   // start other processors
   kinit2(P2V(4*1024*1024), P2V(PHYSTOP)); // must come after startothers()
   userinit();      // first user process
+  //create_kernel_process("swapout", swapout); // set up the swapper.
+  //create_kernel_process("swapin", swapin);
   mpmain();        // finish this processor's setup
 }
 
@@ -83,7 +85,7 @@ startothers(void)
     // is running in low  memory, so we use entrypgdir for the APs too.
     stack = kalloc();
     *(void**)(code-4) = stack + KSTACKSIZE;
-    *(void(**)(void))(code-8) = mpenter;
+    *(void**)(code-8) = mpenter;
     *(int**)(code-12) = (void *) V2P(entrypgdir);
 
     lapicstartap(c->apicid, V2P(code));
diff --git a/memlayout.h b/memlayout.h
index d1615f7..850fd7c 100644
--- a/memlayout.h
+++ b/memlayout.h
@@ -1,7 +1,7 @@
 // Memory layout
 
 #define EXTMEM  0x100000            // Start of extended memory
-#define PHYSTOP 0xE000000           // Top physical memory
+#define PHYSTOP 0x400000           // Top physical memory
 #define DEVSPACE 0xFE000000         // Other devices are at high addresses
 
 // Key addresses for address space layout (see kmap in vm.c for layout)
@@ -9,7 +9,7 @@
 #define KERNLINK (KERNBASE+EXTMEM)  // Address where kernel is linked
 
 #define V2P(a) (((uint) (a)) - KERNBASE)
-#define P2V(a) ((void *)(((char *) (a)) + KERNBASE))
+#define P2V(a) (((void *) (a)) + KERNBASE)
 
 #define V2P_WO(x) ((x) - KERNBASE)    // same as V2P, but without casts
 #define P2V_WO(x) ((x) + KERNBASE)    // same as P2V, but without casts
diff --git a/memtest1.c b/memtest1.c
new file mode 100644
index 0000000..74046f1
--- /dev/null
+++ b/memtest1.c
@@ -0,0 +1,73 @@
+#include "param.h"
+#include "types.h"
+#include "stat.h"
+#include "user.h"
+#include "fs.h"
+#include "fcntl.h"
+#include "syscall.h"
+#include "traps.h"
+#include "memlayout.h"
+
+char buf[8192];
+char name[3];
+char *echoargv[] = { "echo", "ALL", "TESTS", "PASSED", 0 };
+int stdout = 1;
+#define TOTAL_MEMORY (2 << 20) + (1 << 18) + (1 << 17)
+
+void
+mem(void)
+{
+	void *m1 = 0, *m2, *start;
+	uint cur = 0;
+	uint count = 0;
+	uint total_count;
+
+	printf(1, "mem test\n");
+
+	m1 = malloc(4096);
+	if (m1 == 0)
+		goto failed;
+	start = m1;
+
+	while (cur < TOTAL_MEMORY) {
+		m2 = malloc(4096);
+		if (m2 == 0)
+			goto failed;
+		*(char**)m1 = m2;
+		((int*)m1)[2] = count++;
+		printf(1, "CurrCount: %d\n", ((int*)m1)[2]);
+		m1 = m2;
+		cur += 4096;
+	}
+
+	((int*)m1)[2] = count;
+	total_count = count;
+	printf(1, "\n\nWhile Loop Over\n");
+
+	count = 0;
+	m1 = start;
+
+	while (count != total_count) {
+		if (((int*)m1)[2] != count)
+		{
+			printf(1, "CurrCount: %d\n", count);
+			goto failed;
+		}
+		m1 = *(char**)m1;
+		count++;
+	}
+
+	printf(1, "mem ok %d\n", bstat());
+	exit();
+failed:
+	printf(1, "test failed!\n");
+	exit();
+}
+
+int
+main(int argc, char *argv[])
+{
+	printf(1, "memtest starting\n");
+	mem();
+	return 0;
+}
diff --git a/memtest2.c b/memtest2.c
new file mode 100644
index 0000000..513f654
--- /dev/null
+++ b/memtest2.c
@@ -0,0 +1,55 @@
+#include "param.h"
+#include "types.h"
+#include "stat.h"
+#include "user.h"
+#include "fs.h"
+#include "fcntl.h"
+#include "syscall.h"
+#include "traps.h"
+#include "memlayout.h"
+
+char buf[8192];
+char name[3];
+char *echoargv[] = { "echo", "ALL", "TESTS", "PASSED", 0 };
+int stdout = 1;
+#define TOTAL_MEMORY (1 << 20) + (1 << 18)
+
+void
+mem(void)
+{
+	printf(1,"Test Started");	
+	int pid;
+	printf(1, "\n ** Forking ** \n");
+	int size = 4096;
+	for(int i=0;i<20;++i){
+		pid = fork();
+		if(pid > 0) {wait();}
+		else if(pid < 0) { printf(1, "Fork Failed\n"); }
+		else {
+			for(int j=0;j<10;++j){
+				char *memory = (char*) malloc(size); //4kb;
+				if (memory == 0) goto failed;
+				for(int k=0;k<size;++k){
+					memory[k] = (char)(65+(k%26));
+				}
+				for(int k=0;k<size;++k){
+					if(memory[k] != (char)(65+(k%26))) goto failed;
+				}
+			}
+		}
+	}
+	printf(1, "Memory OKKKK %d\n", bstat());
+	exit();
+	
+failed:
+	printf(1, "test failed!\n");
+	exit();
+}
+
+int
+main(int argc, char *argv[])
+{
+	printf(1, "Memtest starting\n");
+	mem();
+	return 0;
+}
diff --git a/memtest3.c b/memtest3.c
new file mode 100644
index 0000000..61ad2d1
--- /dev/null
+++ b/memtest3.c
@@ -0,0 +1,16 @@
+#include "param.h"
+#include "types.h"
+#include "stat.h"
+#include "user.h"
+#include "fs.h"
+#include "fcntl.h"
+#include "syscall.h"
+#include "traps.h"
+#include "memlayout.h"
+
+int
+main(int argc, char *argv[])
+{
+	printf(1, "Num swapped blocks:%d\n", bstat());
+	exit();
+}
diff --git a/mmu.h b/mmu.h
index a82d8e2..0a4997a 100644
--- a/mmu.h
+++ b/mmu.h
@@ -2,11 +2,39 @@
 // x86 memory management unit (MMU).
 
 // Eflags register
+#define FL_CF           0x00000001      // Carry Flag
+#define FL_PF           0x00000004      // Parity Flag
+#define FL_AF           0x00000010      // Auxiliary carry Flag
+#define FL_ZF           0x00000040      // Zero Flag
+#define FL_SF           0x00000080      // Sign Flag
+#define FL_TF           0x00000100      // Trap Flag
 #define FL_IF           0x00000200      // Interrupt Enable
+#define FL_DF           0x00000400      // Direction Flag
+#define FL_OF           0x00000800      // Overflow Flag
+#define FL_IOPL_MASK    0x00003000      // I/O Privilege Level bitmask
+#define FL_IOPL_0       0x00000000      //   IOPL == 0
+#define FL_IOPL_1       0x00001000      //   IOPL == 1
+#define FL_IOPL_2       0x00002000      //   IOPL == 2
+#define FL_IOPL_3       0x00003000      //   IOPL == 3
+#define FL_NT           0x00004000      // Nested Task
+#define FL_RF           0x00010000      // Resume Flag
+#define FL_VM           0x00020000      // Virtual 8086 mode
+#define FL_AC           0x00040000      // Alignment Check
+#define FL_VIF          0x00080000      // Virtual Interrupt Flag
+#define FL_VIP          0x00100000      // Virtual Interrupt Pending
+#define FL_ID           0x00200000      // ID flag
 
 // Control Register flags
 #define CR0_PE          0x00000001      // Protection Enable
+#define CR0_MP          0x00000002      // Monitor coProcessor
+#define CR0_EM          0x00000004      // Emulation
+#define CR0_TS          0x00000008      // Task Switched
+#define CR0_ET          0x00000010      // Extension Type
+#define CR0_NE          0x00000020      // Numeric Errror
 #define CR0_WP          0x00010000      // Write Protect
+#define CR0_AM          0x00040000      // Alignment Mask
+#define CR0_NW          0x20000000      // Not Writethrough
+#define CR0_CD          0x40000000      // Cache Disable
 #define CR0_PG          0x80000000      // Paging
 
 #define CR4_PSE         0x00000010      // Page size extension
@@ -19,7 +47,7 @@
 #define SEG_TSS   5  // this process's task state
 
 // cpu->gdt[NSEGS] holds the above segments.
-#define NSEGS     6
+#define NSEGS     7
 
 #ifndef __ASSEMBLER__
 // Segment Descriptor
@@ -54,11 +82,23 @@ struct segdesc {
 
 // Application segment type bits
 #define STA_X       0x8     // Executable segment
+#define STA_E       0x4     // Expand down (non-executable segments)
+#define STA_C       0x4     // Conforming code segment (executable only)
 #define STA_W       0x2     // Writeable (non-executable segments)
 #define STA_R       0x2     // Readable (executable segments)
+#define STA_A       0x1     // Accessed
 
 // System segment type bits
+#define STS_T16A    0x1     // Available 16-bit TSS
+#define STS_LDT     0x2     // Local Descriptor Table
+#define STS_T16B    0x3     // Busy 16-bit TSS
+#define STS_CG16    0x4     // 16-bit Call Gate
+#define STS_TG      0x5     // Task Gate / Coum Transmitions
+#define STS_IG16    0x6     // 16-bit Interrupt Gate
+#define STS_TG16    0x7     // 16-bit Trap Gate
 #define STS_T32A    0x9     // Available 32-bit TSS
+#define STS_T32B    0xB     // Busy 32-bit TSS
+#define STS_CG32    0xC     // 32-bit Call Gate
 #define STS_IG32    0xE     // 32-bit Interrupt Gate
 #define STS_TG32    0xF     // 32-bit Trap Gate
 
@@ -84,6 +124,7 @@ struct segdesc {
 #define NPTENTRIES      1024    // # PTEs per page table
 #define PGSIZE          4096    // bytes mapped by a page
 
+#define PGSHIFT         12      // log2(PGSIZE)
 #define PTXSHIFT        12      // offset of PTX in a linear address
 #define PDXSHIFT        22      // offset of PDX in a linear address
 
@@ -94,7 +135,13 @@ struct segdesc {
 #define PTE_P           0x001   // Present
 #define PTE_W           0x002   // Writeable
 #define PTE_U           0x004   // User
+#define PTE_PWT         0x008   // Write-Through
+#define PTE_PCD         0x010   // Cache-Disable
+#define PTE_A           0x020   // Accessed
+#define PTE_D           0x040   // Dirty
 #define PTE_PS          0x080   // Page Size
+#define PTE_MBZ         0x180   // Bits must be zero
+#define PTE_SWAPPED     0x200   // If the physical page it is pointing to is swapped to disk
 
 // Address in page table or page directory entry
 #define PTE_ADDR(pte)   ((uint)(pte) & ~0xFFF)
@@ -144,13 +191,14 @@ struct taskstate {
   ushort iomb;       // I/O map base address
 };
 
+// PAGEBREAK: 12
 // Gate descriptors for interrupts and traps
 struct gatedesc {
   uint off_15_0 : 16;   // low 16 bits of offset in segment
   uint cs : 16;         // code segment selector
   uint args : 5;        // # args, 0 for interrupt/trap gates
   uint rsv1 : 3;        // reserved(should be zero I guess)
-  uint type : 4;        // type(STS_{IG32,TG32})
+  uint type : 4;        // type(STS_{TG,IG32,TG32})
   uint s : 1;           // must be 0 (system)
   uint dpl : 2;         // descriptor(meaning new) privilege level
   uint p : 1;           // Present
diff --git a/old_swap.c b/old_swap.c
new file mode 100644
index 0000000..58e37db
--- /dev/null
+++ b/old_swap.c
@@ -0,0 +1,772 @@
+#include "types.h"
+#include "defs.h"
+#include "param.h"
+#include "memlayout.h"
+#include "mmu.h"
+#include "x86.h"
+#include "proc.h"
+#include "spinlock.h"
+#include "swap.h"
+#include "stat.h"
+#include "fs.h"
+#include "sleeplock.h"
+#include "file.h"
+
+#define PAGES_LOW 100
+#define PAGES_HIGH 1000
+
+// Type will always be 0, but other types may also be added
+struct swap_info_struct swap_info[1];
+struct spinlock swaplock;
+
+// Forward declarations
+swp_entry_t get_swap_page(void);
+int scan_swap_map(struct swap_info_struct*);
+void lru_list_initialize();
+void lru_cache_del(pte_t, uint);
+
+#define SWAPFILE_CLUSTER 16
+//#define SWAPFILE_CLUSTER 3
+
+void kswapinit()
+{
+	unsigned int swapmap_bytes_needed = SWAPFILE_PAGES * sizeof(unsigned short);
+	cprintf("kernel: Initializing swap info\n");
+
+	memset(&swap_info[0],0,sizeof(struct swap_info_struct));
+	swap_info[0].pages = swap_info[0].max = SWAPFILE_PAGES;
+	swap_info[0].max--;
+	swap_info[0].swap_map_pages = 1 + (swapmap_bytes_needed / PGSIZE);
+	swap_info[0].flags = SWP_WRITEOK;
+	swap_info[0].highest_bit = SWAPFILE_PAGES - 1;
+	swap_info[0].cluster_nr = SWAPFILE_CLUSTER;
+
+	initlock(&swaplock,"swaplock");
+	initlock(&swap_info[0].sdev_lock,"sdev_lock");
+
+	cprintf("kernel: swapmap bytes needed: %d\n",swapmap_bytes_needed);
+	cprintf("kernel: swapmap pages needed: %d\n",swap_info[0].swap_map_pages);
+
+	for (int x = 0; x < swap_info[0].swap_map_pages; x++)
+	{
+		// We assume here that kalloc'ed pages will happen in a sequence from high to low. This method should be executed early enough
+		// in xv6 initialization, so this should happen every time. Hence we can do a strightforward implementation.
+		
+		// Example scenario:
+		// 4 pages needed for the swap map total, so 4 passes thru the loop
+		// 1st page allocated at 0x804FF000
+		// 2nd page allocated at 0x804FE000
+		// 3rd page allocated at 0x804FD000
+		// 4th page allocated at 0x804FC000. Swap map pointer set to 0x804FC000 since this is the last page.
+		
+		// In this case we have the range for the swap map allocated from 0x804FC000 to 0x804FFFFF for a total of 16k
+
+		char *new_kalloc_page = kalloc();
+		memset(new_kalloc_page,0,PGSIZE);
+		cprintf("kernel: Allocating page for swap map at address 0x%p\n",new_kalloc_page);
+		
+		if (x == swap_info[0].swap_map_pages - 1)
+		{
+			// Allocate & zero out this section of the map
+			swap_info[0].swap_map = (unsigned short*)new_kalloc_page;
+			cprintf("kernel: Swap map pointer set to address 0x%p\n",new_kalloc_page);
+		}
+	}
+
+	lru_list_initialize();
+	cprintf("kernel: Done initializing swap info\n");
+}
+
+void print_swap_map()
+{
+	cprintf("Swap map(lb==%d, hb==%d):\n",swap_info[0].lowest_bit,swap_info[0].highest_bit);
+
+	for (int x = 0; x < SWAPFILE_PAGES; x++)
+		cprintf("%d ",swap_info[0].swap_map[x]);
+
+	cprintf("\n");
+}
+
+unsigned int swap_page_total_count() {
+	return SWAPFILE_PAGES;
+}
+
+unsigned int swap_page_count() {
+  return swap_info[0].pages;
+}
+
+inline unsigned int swap_refcount(unsigned long offset)
+{
+	if (offset > SWAPFILE_PAGES)
+		panic("swap_refcount");
+	return swap_info[0].swap_map[offset];
+}
+
+int swap_duplicate(swp_entry_t entry)
+{
+	unsigned int offset = SWP_OFFSET(entry);
+
+	if (offset > SWAPFILE_PAGES)
+		panic("swap_duplicate");
+	
+	swap_list_lock();
+	++swap_info[0].swap_map[offset];	
+	swap_list_unlock();
+	return swap_info[0].swap_map[offset];
+}
+
+int swap_entry_free(struct swap_info_struct *p, unsigned long offset)
+{
+	int count = p->swap_map[offset];
+
+	if (count < SWAP_MAP_MAX) {
+		count--;
+		p->swap_map[offset] = count;
+		if (!count) {
+			if (offset < p->lowest_bit)
+				p->lowest_bit = offset;
+			if (offset > p->highest_bit)
+				p->highest_bit = offset;
+			p->pages++;
+		}
+	}
+	return count;
+}
+
+int swap_free(swp_entry_t entry)
+{
+	int retval = 0;
+	struct swap_info_struct * p = &swap_info[0];
+
+	swap_list_lock();
+	retval = swap_entry_free(p, SWP_OFFSET(entry));
+	swap_list_unlock();
+
+	return retval;
+}
+
+int swap_free_nolocks(swp_entry_t entry) {
+	return swap_entry_free(&swap_info[0], SWP_OFFSET(entry));
+}
+
+// Frees all swap pages
+void free_swap_pages(struct proc *currproc)
+{
+  swap_list_lock();
+  for (int index1 = 0; index1 < NPDENTRIES; index1++)
+  {
+    pde_t *pde = &(currproc->pgdir[index1]);
+
+    if (*pde & PTE_P && index1 < 512)
+    {
+      pde_t *pgtab = (pte_t*)P2V(PTE_ADDR(*pde));
+
+      for (int index2 = 11; index2 < NPTENTRIES; index2++)
+      {
+        if (!(pgtab[index2] & PTE_P) && (pgtab[index2] & PTE_U))
+        {
+			// Check if this page is swapped out
+			swp_entry_t this_entry = pte_to_swp_entry(pgtab[index2]);
+			uint offset = SWP_OFFSET(this_entry);
+
+			if (offset < SWAPFILE_PAGES && swap_info[0].swap_map[offset] != 0)
+			{
+				cprintf("process [%s] exiting. freeing slot entry %d. New refcount==%d\n",currproc->name,offset,swap_free_nolocks(this_entry));
+			}
+        }
+      }
+    }
+  }
+  swap_list_unlock();
+}
+
+int swap_out(pte_t *mapped_victim_pte, unsigned int offset)
+{
+	struct swap_info_struct *p = &swap_info[0];
+	int file_offset = offset + 1, retval = -1;
+	uint old_offset;
+	char *kernel_addr = P2V(PTE_ADDR(*mapped_victim_pte));
+
+	if(p->swap_file == NULL)
+		return -1;
+
+	old_offset = p->swap_file->off;
+
+	// Quick and dirty hack for now. Need a lock-protected state variable later
+	myproc()->pages_swapped_out++;
+
+	// Write contents to swapfile
+	p->swap_file->off = (unsigned int)(file_offset * PGSIZE);
+  	retval = filewrite(p->swap_file,kernel_addr,PGSIZE);
+  	p->swap_file->off = old_offset;
+
+	return retval;
+}
+
+// My own method. Swap a page into main memory from the specified slot
+int swap_in(void *page_addr, unsigned int offset)
+{
+	struct swap_info_struct *p = &swap_info[0];
+	int file_offset = offset + 1, retval = -1;
+	uint old_offset;
+
+	if (p->swap_file == NULL)
+	// SWAPFILE pointer not set yet with ksetswapfileptr() system call
+		return -1;
+
+	old_offset = p->swap_file->off;
+
+	// Quick and dirty hack for now. Need a lock-protected state variable later
+	myproc()->pages_swapped_out--;
+
+	// Read contents from swapfile
+	p->swap_file->off = (unsigned int)(file_offset * PGSIZE);
+	retval = fileread(p->swap_file,page_addr,PGSIZE);
+	p->swap_file->off = old_offset;
+
+	return retval;
+}
+
+swp_entry_t get_swap_page()
+{
+	struct swap_info_struct * p;
+	unsigned long offset;
+	swp_entry_t entry;
+	int type;
+
+	entry.val = 0;	// Out of memory 
+	swap_list_lock();
+	type = 0;
+	if (type < 0)
+		goto out;
+	if (swap_info[0].pages <= 0)
+		goto out;
+
+	while (1) {
+		p = &swap_info[type];
+		if ((p->flags & SWP_WRITEOK) == SWP_WRITEOK) {
+			swap_device_lock(p);
+
+			//cprintf("before scan_swap_map\n");
+			offset = scan_swap_map(p);
+			//cprintf("after scan_swap_map. offset==%d\n",offset);
+			
+			swap_device_unlock(p);
+			if (offset >= 0) {
+				entry = SWP_ENTRY(type,offset);
+				goto out;
+			}
+		}
+	}
+out:
+	swap_list_unlock();
+	return entry;
+}
+
+inline void ksetswapfileptr(struct file *f)
+{
+  cprintf("kernel: Swap file pointer set! Address of file pointer: 0x%p\n",f);
+  swap_info[0].swap_file = filedup(f);
+}
+
+inline int scan_swap_map(struct swap_info_struct *si)
+{
+	unsigned long offset;
+	/* We try to cluster swap pages by allocating them sequentially in swap. Once we've allocated SWAPFILE_CLUSTER pages this way, however, we resort to
+	 * first-free allocation, starting a new cluster. This prevents us from scattering swap pages all over the entire
+	 * swap partition, so that we reduce overall disk seek times between swap pages. */
+	if (si->cluster_nr) {
+		while (si->cluster_next <= si->highest_bit) {
+			offset = si->cluster_next++;
+			if (si->swap_map[offset])
+				continue;
+			si->cluster_nr--;
+			goto got_page;
+		}
+	}
+	si->cluster_nr = SWAPFILE_CLUSTER;
+
+	/* try to find an empty (even not aligned) cluster. */
+	offset = si->lowest_bit;
+ check_next_cluster:
+	if (offset+SWAPFILE_CLUSTER-1 <= si->highest_bit)
+	{
+		int nr;
+		for (nr = offset; nr < offset+SWAPFILE_CLUSTER; nr++)
+			if (si->swap_map[nr])
+			{
+				offset = nr+1;
+				goto check_next_cluster;
+			}
+		goto got_page;
+	}
+
+	/* No luck, so now go finegrined as usual. -Andrea */
+	for (offset = si->lowest_bit; offset <= si->highest_bit ; offset++) {
+		if (si->swap_map[offset])
+			continue;
+		si->lowest_bit = offset+1;
+	got_page:
+		if (offset == si->lowest_bit)
+			si->lowest_bit++;
+		if (offset == si->highest_bit)
+			si->highest_bit--;
+		if (si->lowest_bit > si->highest_bit) {
+			si->lowest_bit = si->max;
+			si->highest_bit = 0;
+		}
+		si->swap_map[offset] = 1;
+		si->pages--;
+		si->cluster_next = offset+1;
+		return offset;
+	}
+	si->lowest_bit = si->max;
+	si->highest_bit = 0;
+	return 0;
+}
+
+// LRU section
+struct lru_list_entry {
+	pte_t addr;
+	struct lru_list_entry *next;
+};
+
+struct lru_list_struct {
+	struct lru_list_entry *active_list;
+	struct lru_list_entry *inactive_list;
+	struct spinlock lru_lock;
+	unsigned long nr_active_pages;
+	unsigned long nr_inactive_pages;	
+};
+
+// Note that we can have a large number of entries in the LRU list, which may overflow the kernel stack.
+// As a result, we need a subsystem to manage the doling out of LRU entries to be used, which we will dub the LRU bank
+
+// Needed to figure out how many pages to allocate for LRU list bank
+// Assume 12 bytes for header (prev & next pointers and count)
+#define LRU_HEADER_SIZE 12
+#define LRU_ENTRIES_PER_PAGE ((PGSIZE - LRU_HEADER_SIZE) / sizeof(struct lru_list_entry))
+
+struct lru_bank_page {
+	// Contains blocks of LRU entries to be given out when needed
+	struct lru_bank_page *prev;
+	struct lru_bank_page *next;
+	unsigned int used;
+
+	struct lru_list_entry slots[LRU_ENTRIES_PER_PAGE];
+};
+
+// Main container for LRU lists
+struct lru_list_struct lru_list;
+#define lru_list_lock()     acquire(&lru_list.lru_lock);
+#define lru_list_unlock()   release(&lru_list.lru_lock);
+
+struct lru_bank_page *lru_bank = NULL;
+
+void lru_list_initialize()
+{
+	cprintf("kernel: Initializing LRU list container.\n");
+
+	lru_bank = (struct lru_bank_page*)kalloc();
+
+	if (!lru_bank)
+		panic("Unable to allocate LRU bank!");
+	
+	memset(lru_bank,0,sizeof(struct lru_bank_page));
+
+	cprintf("kernel: First page of LRU entry bank created at 0x%p\n", lru_bank);
+
+	cprintf("kernel: Initializing LRU active & inactive lists\n", lru_bank);
+	lru_list.active_list = NULL;
+	lru_list.inactive_list = NULL;
+	lru_list.nr_active_pages = 0;
+	lru_list.nr_inactive_pages = 0;
+	initlock(&lru_list.lru_lock,"lru_lock");
+
+	cprintf("kernel: LRU entries per page: %d\n", LRU_ENTRIES_PER_PAGE);
+}
+
+struct lru_list_entry *lru_bank_get_new()
+// Returns a fresh LRU entry to be used
+{
+	struct lru_list_entry *retval = NULL;
+	struct lru_bank_page *lb_curr = lru_bank;
+	struct lru_bank_page *lb_last = lb_curr;
+
+	while (lb_curr)
+	{
+		uint exit = 0;
+
+		if (lb_curr->used < LRU_ENTRIES_PER_PAGE)
+		{
+			// Take an entry from the current page
+			for (int x = 0; x < LRU_ENTRIES_PER_PAGE; x++)
+			{
+				if (lb_curr->slots[x].addr == 0)
+				// Found free entry
+				{
+					retval = &lb_curr->slots[x];
+					lb_curr->used++;
+					exit = 1;
+					break;
+				}
+			}
+		}
+
+		if (exit > 0)
+			break;
+
+		// No free entries found. Try next page
+		lb_last = lb_curr;
+		lb_curr = lb_curr->next;
+	}
+
+	if (retval == NULL)
+	// All LRU entries in all currently allocated bank pages are in use. Create a new bank page
+	{
+		if (lb_last == NULL)
+			panic("lru_bank_get_new(): lb_last != NULL assertion failed");
+
+		// Create new bank page
+		lb_curr = lb_last->next = (struct lru_bank_page*)kalloc();
+		lb_curr->prev = lb_last;
+		memset(lb_curr,0,PGSIZE);
+
+		// Assign new LRU item
+		retval = &lb_curr->slots[0];
+		lb_curr->used++;
+	}
+
+	//cprintf("kernel: Got new LRU entry at address 0x%p\n",retval);
+
+	retval->addr = 0;
+	retval->next = NULL;
+	return retval;
+}
+
+// Finds the LRU bank page of the associated entry. Should never return NULL
+struct lru_bank_page *lru_bank_find_page(struct lru_list_entry *entry)
+{
+	struct lru_bank_page *retval = NULL;
+	struct lru_bank_page *currpg = lru_bank;
+
+	while (currpg && retval == NULL)
+	{
+		if ((uint)entry >= (uint)currpg && (uint)entry < (uint)currpg + PGSIZE)
+			retval = currpg;
+
+		currpg = currpg->next;
+	}
+
+	return retval;
+}
+
+// Removes target entry and releases it back into the LRU bank. Does not change the next field
+void lru_bank_release(struct lru_list_entry *target)
+{
+	//cprintf("kernel: lru_bank_page() finding LRU entry with target==0x%p,target->addr==0x%p\n",target,target->addr);
+	struct lru_bank_page *currpg = lru_bank_find_page(target);
+	
+	if (currpg == NULL)
+		panic("lru_bank_release()");
+	
+	// Blank out this LRU entry and free it for use
+	target->addr = 0;
+	currpg->used--;
+}
+
+// Add a cold page to the front of the inactive_list. Will be moved to active_list with a call to mark_page_accessed()
+// if the page is known to be hot, such as when a page is faulted in (pageHot > 0).
+void lru_cache_add(pde_t addr, int pageHot)
+{
+	cprintf("kernel: Adding %s pte at kernel address 0x%p to LRU cache\n",(pageHot == 0 ? "cold" : "hot"),addr);
+	lru_list_lock();
+
+	struct lru_list_entry *new_entry = lru_bank_get_new();
+
+	//cprintf("kernel: lru_cache_add(): new_entry==0x%p\n",new_entry);
+
+	new_entry->addr = addr;
+	if (pageHot <= 0)
+	{
+		// Add cold page to front of inactive list
+		new_entry->next = lru_list.inactive_list;
+		lru_list.inactive_list = new_entry;
+
+		lru_list.nr_inactive_pages++;
+	}
+	else {
+		// Since we know the page is hot, put it in the front of the active list right now
+		new_entry->next = lru_list.active_list;
+		lru_list.active_list = new_entry;
+		lru_list.nr_active_pages++;
+		// *pte |= PTE_A; <----- Add accessed bit (reference purposes)
+	}
+
+	// Clear accessed bit (although this is pointless if the page is hot and this is called from trap.c as a page fault)
+	pte_t *pte = (pte_t*)addr;
+	*pte &= ~PTE_A;
+	lru_list_unlock();
+}
+
+// Removes a page from the LRU lists by calling either del_page_from_active_list()
+// or del_page_from_inactive_list(), whichever is appropriate.
+// The parameter rangeSize deletes all addresses between (addr) and (addr + rangeSize). Set rangeSize to 0 to specify a single address
+void lru_cache_del(pte_t addr, uint rangeSize)
+{
+	lru_list_lock();
+	struct lru_list_entry *curr = NULL;
+	struct lru_list_entry *prev = NULL;
+
+	// Search active list first
+	curr = lru_list.active_list;
+	prev = curr;
+
+	while (curr)
+	{
+		if (curr->addr >= addr && curr->addr <= ((uint)addr + rangeSize))
+		{
+			// Remove the entry
+			cprintf("kernel: Removing LRU entry for PTE at 0x%p from active list\n",*curr);
+			lru_bank_release(curr);
+			lru_list.nr_active_pages--;
+			
+			if (lru_list.active_list == curr)
+				lru_list.active_list = curr->next;
+			else
+				prev->next = curr->next;
+
+			if (rangeSize == 0) {
+				lru_list_unlock();
+				return;
+			}
+		}
+		prev = curr;
+		curr = curr->next;
+	}
+
+	// Now search inactive list
+	curr = lru_list.inactive_list;
+	prev = curr;
+
+	while (curr)
+	{
+		if (curr->addr >= addr && curr->addr <= ((uint)addr + rangeSize))
+		{
+			// Remove the entry
+			cprintf("kernel: Removing LRU entry for PTE at 0x%p from inactive list\n",*curr);
+			lru_bank_release(curr);
+			lru_list.nr_inactive_pages--;
+			
+			if (lru_list.inactive_list == curr)
+				lru_list.inactive_list = curr->next;
+			else
+				prev->next = curr->next;
+
+			if (rangeSize == 0)
+			{
+				lru_list_unlock();
+				return;
+			}
+		}
+		prev = curr;
+		curr = curr->next;
+	}
+
+	lru_list_unlock();
+	return;
+}
+
+// Removes a page from the inactive_list and places it on active_list. 
+// It is very rarely called directly as the caller has to know the page is on inactive_list. mark_page_accessed() should be used instead
+void activate_page(pte_t addr)
+{
+	pte_t *pte = (pte_t*)addr;
+	// Clear accessed bit
+	*pte &= ~PTE_A;
+	lru_cache_del(addr,0);
+	lru_cache_add(addr,1);
+}
+
+// Mark that the page has been accessed. Implementation more complex in linux but here we just call activate_page()
+void mark_page_accessed(pte_t addr)
+{
+	activate_page(addr);
+}
+
+// Method to list all pages in the LRU cache. Used for demonstration/debugging purposes
+void print_lru()
+{
+	struct lru_list_entry *entry = lru_list.active_list;
+	unsigned int index = 0;
+	cprintf("*** LRU table ***\n");
+	cprintf("*** Active list ***\n");
+
+	while (entry)
+	{
+		pte_t *pte = (pte_t*)entry->addr;
+		cprintf("Entry #%d: PTE addr==0x%p, accessed bit: %d\n",index,entry->addr,(*pte & PTE_A));
+		index++;
+		entry = entry->next;
+	}
+
+	cprintf("*** Inactive list ***\n");
+	entry = lru_list.inactive_list;
+	index = 0;
+
+	while (entry)
+	{
+		pte_t *pte = (pte_t*)entry->addr;
+		cprintf("Entry #%d: PTE addr==0x%p, accessed bit: %d\n",index,entry->addr,(*pte & PTE_A));
+		index++;
+		entry = entry->next;
+	}	
+	cprintf("*** End of LRU table ***\n");
+}
+
+// Simplified version of the refill_inactive() method on linux. Here, we do everything in this method.
+// Our goal is to make the active list comprise 2/3 of the total, and the inactive list the remaining 1/3
+void refill_inactive()
+{
+	// nr_pages is the # of pages we want to swap out
+	unsigned long nr_pages = 1;
+	unsigned long ratio = 0;
+	unsigned long index = 0;
+	unsigned long total_lru_pages = lru_list.nr_active_pages + lru_list.nr_inactive_pages;
+	unsigned long active_target_count;
+	struct lru_list_entry *entry = lru_list.active_list;
+
+	// Get # of pages to move
+	// Per the docs, the active needs needs to be 2/3 the size of the inactive list
+	// Hence, the active list is 2/5 the total and the inactive 3/5 of the total
+	active_target_count = 2 * total_lru_pages;
+	active_target_count /= 5;
+	ratio = lru_list.nr_active_pages - active_target_count;
+
+	if (ratio < 0)
+		ratio = 0;
+
+	cprintf("kernel: refill_inactive() found: atc==%d, nr_pages==%d, active==%d, inactive==%d, ratio==%d \n",active_target_count, nr_pages,lru_list.nr_active_pages,lru_list.nr_inactive_pages,ratio);
+	cprintf("kernel: refill_inactive() moving %d pages from active to inactive list\n",ratio);
+
+	// Move the pages
+	while (entry != NULL)
+	{
+		// Check for pages which have been accessed
+		pte_t addr = entry->addr;
+		pte_t *pte = (pte_t*)entry->addr;
+		struct lru_list_entry *nextentry = entry->next;
+		uint is_active = (*pte & PTE_A);
+
+		// We're either going to move the page to the front of the active list or to the inactive list
+		// In either case, we'll delete the one we have now
+
+		if (!(is_active) && ratio > 0)
+		{
+			// Accessed bit is not set, so page isn't hot anymore. Move to inactive list
+			cprintf("kernel: moving active LRU entry to inactive list\n");
+			// Clear accessed bit
+			*pte &= ~PTE_A;		
+			lru_cache_del(addr,0);
+			lru_cache_add(addr,0);
+			// Add accessed bit
+			//*pte |= PTE_A;
+			ratio--;
+		}
+		else if (is_active)
+		{
+			// Page is still hot, clear accessed bit & move to front of active list
+			cprintf("kernel: moving hot LRU entry to front of active list\n");
+			mark_page_accessed(entry->addr);
+		}
+		entry = nextentry;
+		index++;
+	}
+}
+
+// Place any inactive pages accessed back into the active list
+void refill_active()
+{
+	struct lru_list_entry *entry = lru_list.inactive_list;
+
+	while (entry != NULL)
+	{
+		// Check for pages which have been accessed
+		pte_t *pte = (pte_t*)entry->addr;
+		struct lru_list_entry *nextentry = entry->next;
+		// We're either going to move the page to the front of the active list or to the inactive list
+		// In either case, we'll delete the one we have now
+
+		// Accessed bit is set, so page is now hot. Move to active list
+		if (*pte & PTE_A)
+		{
+			cprintf("kernel: moving hot LRU entry to front of active list\n");
+			mark_page_accessed(entry->addr);
+		}
+		entry = nextentry;
+	}
+}
+
+// Rotates the active and inactive LRU lists loosely according to the simplified LRQ2 algorithm
+void lru_rotate_lists()
+{
+	refill_inactive();
+	refill_active();
+}
+
+void lru_remove_proc_pages(struct proc *currproc)
+{
+  // Standard page directory crawl
+  for (int index1 = 0; index1 < NPDENTRIES; index1++)
+  {
+    pde_t *pde = &(currproc->pgdir[index1]);
+
+    if (*pde & PTE_P && index1 < 512)
+    {
+      pde_t *pgtab = (pte_t*)P2V(PTE_ADDR(*pde));
+
+      cprintf("kernel: Removing LRU entries between 0x%p and 0x%p.\n",pgtab,(uint)pgtab+PGSIZE);
+	  lru_cache_del((uint)pgtab,PGSIZE);
+	  
+    }
+  }
+}
+
+// Returns the address of a page directory entry for the next victim page
+unsigned int *get_victim_page()
+{
+
+	struct lru_list_entry *curr = NULL;
+	struct lru_list_entry *victim_entry = NULL;
+	pte_t *pte = NULL;
+
+	// Try this # of times to rotate the list and find a victim. 
+	int attempts = 2;
+
+	for (int index = 0; index < attempts; index++)
+	{
+		// Give us some fresh inactives
+		lru_rotate_lists();
+		curr = lru_list.inactive_list;
+		while (curr)
+		// This loop gets the last inactive entry that hasn't been accessed
+		{
+			pte = (pte_t*)curr->addr;
+			if (!(*pte & PTE_A) && (*pte & PTE_P))
+				// Page not accessed & is still present in memory. Make this the current victim
+				victim_entry = curr;
+			curr = curr->next;
+		}
+
+		if(victim_entry != NULL)
+			break;
+	}
+	
+	if (victim_entry == NULL)
+		panic("No LRU inactive pages present in physical memory");
+	else {
+		pte = (pte_t*)victim_entry->addr;
+		return (unsigned int*)victim_entry->addr;
+	}
+  	return 0;
+}
diff --git a/paging.c b/paging.c
new file mode 100644
index 0000000..53f361d
--- /dev/null
+++ b/paging.c
@@ -0,0 +1,223 @@
+#include "types.h"
+#include "defs.h"
+#include "param.h"
+#include "memlayout.h"
+#include "mmu.h"
+#include "proc.h"
+#include "x86.h"
+#include "traps.h"
+#include "spinlock.h"
+#include "paging.h"
+#include "fs.h"
+
+static pte_t * walkpgdir(pde_t *pgdir, const void *va, int alloc);
+int deallocuvmxv6(pde_t *pgdir, uint oldsz, uint newsz);
+static int mappages(pde_t *pgdir, void *va, uint size, uint pa, int perm);
+
+struct proc*
+myprocxv6(void) {
+  struct cpu *c;
+  struct proc *p;
+  pushcli();
+  c = mycpu();
+  p = c->proc;
+  popcli();
+  return p;
+}
+
+// Allocate eight consecutive disk blocks. Save the content of the physical page in the pte to the disk blocks and save the block-id into the pte.
+void
+swap_page_from_pte(pte_t *pte)
+{
+	uint physicalAddress=PTE_ADDR(*pte);          //PTE_ADDR returns address in pte
+	if(physicalAddress==0)
+	    cprintf("physicalAddress address is zero\n");
+	uint diskPage=balloc_page(ROOTDEV);
+	write_page_to_disk(ROOTDEV,(char*)P2V(physicalAddress),diskPage);    //write this page 
+
+  /*
+    Store block id and swapped flag in the pte entry whose page was swapped.
+    So, when next time this pte is dereferenced, we know that the page has been swapped
+    and we can bring this page again to memory
+  */
+	*pte = (*pte & 0x000000);              // make pte = null;
+	*pte = (diskPage << 12)| PTE_SWAPPED;
+	*pte = *pte & ~PTE_P;
+
+  /*
+  	WHEN PAGE TABLE ENTRIES ARE MODIFIED, THE HARDWARE STILL USES CACHED ENTRIES IN TLB,
+    SO WE NEED TO INVALIDATE TLB ENTRY USING EITHER invlpg INSTRUCTION OR lcr3
+  */
+
+	kfree(P2V(physicalAddress));
+	cprintf("\nReturning from swap page from pte\n");
+}
+
+/* Select a victim and swap the contents to the disk.*/
+int
+swap_page(pde_t *pgdir)
+{
+  pte_t* pte=select_a_victim(pgdir);              //returns *pte
+  if(pte==0){                                     //If this is true, victim is not found in 1st attempt. Inside this function
+    cprintf("No victim found in 1st attempt. Clearing access bits.");
+    clearaccessbit(pgdir);                        //Accessbits are cleared,
+
+    cprintf("Finding victim again, after clearing access bits of 10%% pages.");
+    pte=select_a_victim(pgdir);                   //then victim is selected again. Victim is found this time.
+
+    if(pte!=0) cprintf("victim found");
+    else cprintf("Not found even in second attempt." );
+  }
+  else{                                           //This else is true, then victim is found in first attempt.
+    cprintf("Victim found in 1st attempt.");
+  }
+
+  swap_page_from_pte(pte);  //swap victim page to disk
+  lcr3(V2P(pgdir));         //This operation ensures that the older TLB entries are flushed
+	return 1;
+}
+
+// Map a physical page to the virtual address addr. If the page table entry points to a swapped block restore the content of the page from the swapped
+// block and free the swapped block.
+
+/*
+i) kalloc a physical page
+ii) map physical page to virtual page (addr)
+iii) Set the access bit of the page (last 12 bits are same in physical and virtual page), so they share the access bit
+*/
+
+void
+map_address(pde_t *pgdir, uint addr)
+{
+	struct proc *curproc = myprocxv6();
+	uint cursz = curproc->sz;
+	uint a = PGROUNDDOWN(rcr2());			            // rounds the address to a multiple of page size (PGSIZE)
+
+  pte_t *pte = walkpgdir(pgdir, (char*)a, 0);
+  int blockid = -1;                             // disk id where the page was swapped
+
+	char *mem = kalloc();                         //allocate a physical page
+
+  if(mem==0){
+		// xv6 swapping 
+    swap_page(pgdir);
+    mem = kalloc();                             // now a physical page has been swapped to disk and free, so this time we will get physical page for sure.
+    cprintf("kalloc success\n");
+	}
+
+  if(pte!=0){
+    if(*pte & PTE_SWAPPED){
+      blockid=getswappedblk(pgdir,a);           // disk id where the page was swapped
+      read_page_from_disk(ROOTDEV, mem, blockid);
+
+      *pte=V2P(mem) | PTE_W | PTE_U | PTE_P;
+      *pte &= ~PTE_SWAPPED;
+      lcr3(V2P(pgdir));
+      bfree_page(ROOTDEV,blockid);
+    }
+    else {
+      memset(mem,0,PGSIZE);
+    	if(mappages(pgdir, (char*)a, PGSIZE, V2P(mem), PTE_P | PTE_W | PTE_U )<0){
+    		panic("allocuvm out of memory xv6 in mappages/n");
+    		deallocuvmxv6(pgdir,cursz+PGSIZE, cursz);
+    		kfree(mem);
+    	}
+    	else{
+    		cprintf("Mappages working\n");
+    	}
+    }
+  }
+
+}
+
+// page fault handler 
+void
+handle_pgfault()
+{
+	unsigned addr;
+	struct proc *curproc = myprocxv6();
+	asm volatile ("movl %%cr2, %0 \n\t" : "=r" (addr));
+	addr &= ~0xfff;
+	map_address(curproc->pgdir, addr);
+}
+
+
+// Return the address of the PTE in page table pgdir that corresponds to virtual address va.  If alloc!=0, create any required page table pages. 
+static pte_t* walkpgdir(pde_t *pgdir, const void *va, int alloc)
+{
+  pde_t *pde;
+  pte_t *pgtab;
+
+  pde = &pgdir[PDX(va)];
+  if(*pde & PTE_P){
+    pgtab = (pte_t*)P2V(PTE_ADDR(*pde));
+  } 
+  else {
+    if(!alloc || (pgtab = (pte_t*)kalloc()) == 0)
+      return 0;
+    
+    // Make sure all those PTE_P bits are zero.
+    memset(pgtab, 0, PGSIZE);
+    
+    // The permissions here are overly generous, but they can
+    // be further restricted by the permissions in the page table
+    // entries, if necessary.
+    *pde = V2P(pgtab) | PTE_P | PTE_W | PTE_U;
+  }
+  return &pgtab[PTX(va)];
+}
+
+// Deallocate user pages to bring the process size from oldsz to
+// newsz.  oldsz and newsz need not be page-aligned, nor does newsz
+// need to be less than oldsz.  oldsz can be larger than the actual
+// process size.  Returns the new process size.
+// If the page was swapped free the corresponding disk block.
+int
+deallocuvmxv6(pde_t *pgdir, uint oldsz, uint newsz)
+{
+  pte_t *pte;
+  uint a, pa;
+
+  if(newsz >= oldsz)
+    return oldsz;
+
+  a = PGROUNDUP(newsz);
+  for(; a  < oldsz; a += PGSIZE){
+    pte = walkpgdir(pgdir, (char*)a, 0);
+    if(!pte)
+      a = PGADDR(PDX(a) + 1, 0, 0) - PGSIZE;
+    else if((*pte & PTE_P) != 0){
+      pa = PTE_ADDR(*pte);
+      if(pa == 0)
+        panic("kfree");
+      char *v = P2V(pa);
+      kfree(v);
+      *pte = 0;
+    }
+  }
+  return newsz;
+}
+
+// Create PTEs for virtual addresses starting at va that refer to
+// physical addresses starting at pa. va and size might not
+// be page-aligned.
+static int
+mappages(pde_t *pgdir, void *va, uint size, uint pa, int perm)
+{
+  char *a, *last;
+  pte_t *pte;
+
+  a = (char*)PGROUNDDOWN((uint)va);
+  last = (char*)PGROUNDDOWN(((uint)va) + size - 1);
+  for(;;){
+    if((pte = walkpgdir(pgdir, a, 1)) == 0)
+      return -1;
+
+    *pte = pa | perm | PTE_P;
+    if(a == last)
+      break;
+    a += PGSIZE;
+    pa += PGSIZE;
+  }
+  return 0;
+}
diff --git a/paging.h b/paging.h
new file mode 100644
index 0000000..f5185e5
--- /dev/null
+++ b/paging.h
@@ -0,0 +1,13 @@
+#ifndef PAGING_H
+#define PAGING_H
+
+void handle_pgfault();
+pte_t* select_a_victim(pde_t *pgdir);
+void clearaccessbit(pde_t *pgdir);
+int getswappedblk(pde_t *pgdir, uint va);
+int swap_page(pde_t *pgdir);
+void swap_page_from_pte(pte_t *pte);
+void map_address(pde_t *pgdir, uint addr);
+pte_t *uva2pte(pde_t *pgdir, uint uva);
+
+#endif
diff --git a/param.h b/param.h
index a7e90ef..dd75020 100644
--- a/param.h
+++ b/param.h
@@ -10,5 +10,5 @@
 #define MAXOPBLOCKS  10  // max # of blocks any FS op writes
 #define LOGSIZE      (MAXOPBLOCKS*3)  // max data blocks in on-disk log
 #define NBUF         (MAXOPBLOCKS*3)  // size of disk block cache
-#define FSSIZE       1000  // size of file system in blocks
+#define FSSIZE       128000  // size of file system in blocks
 
diff --git a/printf.c b/printf.c
index b3298aa..9972b45 100644
--- a/printf.c
+++ b/printf.c
@@ -37,7 +37,7 @@ printint(int fd, int xx, int base, int sgn)
 
 // Print to the given fd. Only understands %d, %x, %p, %s.
 void
-printf(int fd, const char *fmt, ...)
+printf(int fd, char *fmt, ...)
 {
   char *s;
   int c, i, state;
diff --git a/proc.c b/proc.c
index 806b1b1..7fd2aa4 100644
--- a/proc.c
+++ b/proc.c
@@ -6,12 +6,45 @@
 #include "x86.h"
 #include "proc.h"
 #include "spinlock.h"
+#include "paging.h"
+
+#define NOMUTEX  50  
+#define NQUEUE   5  
+
+struct mutex {
+  int owner;  
+  int value;  
+  struct spinlock mlock; 
+};
 
 struct {
   struct spinlock lock;
   struct proc proc[NPROC];
 } ptable;
 
+struct {
+  struct spinlock lock;
+  int chanswapin;
+  int chanswapout;
+} swap;
+
+struct qnode {
+  struct proc *p;
+  struct qnode *next;
+  struct qnode *prev;
+};
+
+struct {
+  struct spinlock qlock;  
+  struct qnode *head;
+  struct qnode *tail;
+  int size;
+} queue[NQUEUE];
+
+struct qnode qnodes[NPROC];
+
+struct qnode *freenode;
+
 static struct proc *initproc;
 
 int nextpid = 1;
@@ -38,10 +71,10 @@ struct cpu*
 mycpu(void)
 {
   int apicid, i;
-  
+
   if(readeflags()&FL_IF)
     panic("mycpu called with interrupts enabled\n");
-  
+
   apicid = lapicid();
   // APIC IDs are not guaranteed to be contiguous. Maybe we should have
   // a reverse map, or reserve a register to store &cpus[i].
@@ -124,7 +157,7 @@ userinit(void)
   extern char _binary_initcode_start[], _binary_initcode_size[];
 
   p = allocproc();
-  
+
   initproc = p;
   if((p->pgdir = setupkvm()) == 0)
     panic("userinit: out of memory?");
@@ -142,14 +175,8 @@ userinit(void)
   safestrcpy(p->name, "initcode", sizeof(p->name));
   p->cwd = namei("/");
 
-  // this assignment to p->state lets other cores
-  // run this process. the acquire forces the above
-  // writes to be visible, and the lock is also needed
-  // because the assignment might not be atomic.
   acquire(&ptable.lock);
-
   p->state = RUNNABLE;
-
   release(&ptable.lock);
 }
 
@@ -158,19 +185,11 @@ userinit(void)
 int
 growproc(int n)
 {
-  uint sz;
   struct proc *curproc = myproc();
 
-  sz = curproc->sz;
-  if(n > 0){
-    if((sz = allocuvm(curproc->pgdir, sz, sz + n)) == 0)
-      return -1;
-  } else if(n < 0){
-    if((sz = deallocuvm(curproc->pgdir, sz, sz + n)) == 0)
-      return -1;
-  }
-  curproc->sz = sz;
-  switchuvm(curproc);
+  if (n < 0 || n > KERNBASE || curproc->sz + n > KERNBASE)
+	  return -1;
+  curproc->sz += n;
   return 0;
 }
 
@@ -180,6 +199,7 @@ growproc(int n)
 int
 fork(void)
 {
+  
   int i, pid;
   struct proc *np;
   struct proc *curproc = myproc();
@@ -211,13 +231,9 @@ fork(void)
   safestrcpy(np->name, curproc->name, sizeof(curproc->name));
 
   pid = np->pid;
-
   acquire(&ptable.lock);
-
   np->state = RUNNABLE;
-
   release(&ptable.lock);
-
   return pid;
 }
 
@@ -275,7 +291,9 @@ wait(void)
   struct proc *p;
   int havekids, pid;
   struct proc *curproc = myproc();
-  
+  pde_t *pgdir;
+
+
   acquire(&ptable.lock);
   for(;;){
     // Scan through table looking for exited children.
@@ -289,13 +307,15 @@ wait(void)
         pid = p->pid;
         kfree(p->kstack);
         p->kstack = 0;
-        freevm(p->pgdir);
+        pgdir = p->pgdir;
+        p->pgdir = 0;
         p->pid = 0;
         p->parent = 0;
         p->name[0] = 0;
         p->killed = 0;
         p->state = UNUSED;
         release(&ptable.lock);
+        freevm(pgdir);
         return pid;
       }
     }
@@ -325,7 +345,7 @@ scheduler(void)
   struct proc *p;
   struct cpu *c = mycpu();
   c->proc = 0;
-  
+
   for(;;){
     // Enable interrupts on this processor.
     sti();
@@ -418,7 +438,7 @@ void
 sleep(void *chan, struct spinlock *lk)
 {
   struct proc *p = myproc();
-  
+
   if(p == 0)
     panic("sleep");
 
@@ -532,3 +552,226 @@ procdump(void)
     cprintf("\n");
   }
 }
+
+/*
+
+int
+mtx_create(int locked)
+{
+  int mtx_id;
+  mtx_id = 0;
+  // check if any more mutexes are available to be created.
+  if (freemtx >= NOMUTEX)
+    return -1;
+
+  // Initialize the spinlock so processes can use it.
+  initlock(&mutexes[mtx_id].mlock, "mutex");
+
+  mtx_id = freemtx;
+  freemtx++;
+
+  // Set lock state based on argument
+  acquire(&mutexes[mtx_id].mlock);
+  if(locked){
+    mutexes[mtx_id].owner = proc->pid;
+    mutexes[mtx_id].value = 1;
+  } else {
+    mutexes[mtx_id].owner = 0;
+    mutexes[mtx_id].value = 0;
+  }
+  release(&mutexes[mtx_id].mlock);
+
+  return mtx_id;
+}
+
+int
+mtx_lock(int lock_id)
+{
+  void *chan;
+  chan = 0;
+  // make sure a mutex was allocated before allowing a lock request to be made.
+  if (lock_id >= freemtx || lock_id < 0)
+    return -1;
+  chan = (void*)(mutexes + lock_id);
+  acquire(&(mutexes[lock_id].mlock));
+
+  // sleep until a lock is acquired on the mutex
+  while (mutexes[lock_id].value > 0 && mutexes[lock_id].owner != proc->pid) {
+    sleep(chan, &(mutexes[lock_id].mlock));
+  }
+
+  // after the lock has been acquired
+  mutexes[lock_id].owner = proc->pid;
+  mutexes[lock_id].value = 1;
+  release(&(mutexes[lock_id].mlock));
+  return 0;
+}
+
+int
+mtx_unlock(int lock_id)
+{
+  void *chan;
+  chan = 0;
+  // check lock_id is valid and if proc owns mutex
+  if (lock_id >= freemtx || lock_id < 0)
+    return -1;
+  if (mutexes[lock_id].owner != proc->pid)
+    return -1;
+
+  chan = (void*)(mutexes + lock_id);
+  acquire(&(mutexes[lock_id].mlock));
+  mutexes[lock_id].value = 0;
+  mutexes[lock_id].owner = -1;
+  release(&(mutexes[lock_id].mlock));
+  wakeup(chan);
+  return 0;
+}
+
+void
+_queue_remove(struct qnode *qn)
+{
+  int priority;
+  priority = qn->p->priority;
+  if (queue[priority].size == 1){
+    queue[priority].head = 0;
+    queue[priority].tail = 0;
+  } else if (queue[priority].head == qn) {
+    qn->next->prev = 0;
+    queue[priority].head = qn->next;
+  } else if (queue[priority].tail == qn) {
+    qn->prev->next = 0;
+    queue[priority].tail = qn->prev;
+  } else {
+    qn->prev->next = qn->next;
+    qn->next = qn->prev;
+  }
+  queue[priority].size--;
+}
+
+void
+_queue_add(struct qnode *qn)
+{
+  int priority;
+  priority = qn->p->priority;
+  if (queue[priority].size == 0){
+    queue[priority].head = qn;
+    queue[priority].tail = qn;
+  } else {
+    queue[priority].tail->next = qn;
+    qn->prev = queue[priority].tail;
+    qn->next = 0;
+    queue[priority].tail = qn;
+  }
+  queue[priority].size++;
+}
+*/
+
+
+/* 
+Pseudo code, written in old_swap.c
+
+void
+swapout(void){
+
+  release(&ptable.lock);
+  cprintf("The swapout swapper has been loaded.\n");
+  for(;;){
+    acquire(&swap.lock);
+    sleep(&swap.chanswapout, &swap.lock);
+   
+    // Find the least recently used page.
+    // Save contents of that page to a file.
+    // Take the memory and put it on kmem.freelist ??? (in kalloc.c)
+    // Get the process to run kalloc again???? (by moving program counter back 
+    // so that it executes kalloc).
+    
+    release(&swap.lock);
+  }
+}
+
+void
+swapin(void){
+  
+  release(&ptable.lock);
+  cprintf("The swapin swapper has been loaded.\n");
+  for(;;){
+    acquire(&swap.lock);
+    sleep(&swap.chanswapin, &swap.lock);
+   
+    // get page table lock.
+    // Find the place to put the page in the page table.
+    // Load contents of page from file into page table.
+    // release page table lock.
+    // delete the file from disk.
+    
+    release(&swap.lock);
+  }
+}
+
+*/
+
+void
+create_kernel_process(const char *name, void (*entrypoint)()){
+  struct proc *np;
+  struct qnode *qn;
+  
+  if ((np = allocproc()) == 0) panic("Failing allocating kernel process");
+  
+  qn = freenode;
+  freenode = freenode->next;
+
+  if(freenode != 0) {
+    freenode->prev = 0;
+  }
+  
+  if((np->pgdir = setupkvm()) == 0){
+    kfree(np->kstack);
+    np->kstack = 0;
+    np->state = UNUSED;
+    panic("Failed setup pgdir for kernel process");
+  }
+  
+  np->sz = PGSIZE;
+  np->parent = initproc; 
+  memset(np->tf, 0, sizeof(*np->tf));
+  np->tf->cs = (SEG_UCODE << 3) | DPL_USER;
+  np->tf->ds = (SEG_UDATA << 3) | DPL_USER;
+  np->tf->es = np->tf->ds;
+  np->tf->ss = np->tf->ds;
+  np->tf->eflags = FL_IF;
+  np->tf->esp = PGSIZE;
+
+  // beginning of initcode.S
+  np->tf->eip = 0;              
+  
+  // Set eax = 0 so that fork return 0 in the child
+  np->tf->eax = 0;
+  np->cwd = namei("/");
+  safestrcpy(np->name, name, sizeof(name));
+  qn->p = np;
+
+  // lock to force the compiler to emit the np-state write last.
+  acquire(&ptable.lock);
+  np->context->eip = (uint)entrypoint;
+  np->state = RUNNABLE;
+  release(&ptable.lock);
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
diff --git a/proc.h b/proc.h
index 1647114..8115044 100644
--- a/proc.h
+++ b/proc.h
@@ -1,3 +1,10 @@
+	// Segments in proc->gdt.	
+#define NSEGS     7	
+#define MAX_PSYC_PAGES 15	
+#define MAX_TOTAL_PAGES 30	
+
+
+
 // Per-CPU state
 struct cpu {
   uchar apicid;                // Local APIC ID
@@ -8,11 +15,28 @@ struct cpu {
   int ncli;                    // Depth of pushcli nesting.
   int intena;                  // Were interrupts enabled before pushcli?
   struct proc *proc;           // The process running on this cpu or null
+  
+  // Cpu-local storage variables; see below	
+  struct cpu *cpu;	
+  //struct proc *proc;           // The currently-running process.
 };
 
 extern struct cpu cpus[NCPU];
 extern int ncpu;
 
+
+	
+// Per-CPU variables, holding pointers to the	
+// current cpu and to the current process.	
+// The asm suffix tells gcc to use "%gs:0" to refer to cpu	
+// and "%gs:4" to refer to proc.  seginit sets up the	
+// %gs segment register so that %gs refers to the memory	
+// holding those two variables in the local cpu's struct cpu.	
+// This is similar to how thread-local variables are implemented	
+// in thread libraries such as Linux pthreads.	
+extern struct cpu *cpu asm("%gs:0");       // &cpus[cpunum()]	
+extern struct proc *proc asm("%gs:4");     // cpus[cpunum()].proc
+
 //PAGEBREAK: 17
 // Saved registers for kernel context switches.
 // Don't need to save all the segment registers (%cs, etc),
@@ -34,6 +58,21 @@ struct context {
 
 enum procstate { UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE };
 
+
+		
+struct pgdesc {	
+  uint swaploc;	
+  int age;	
+  char *va;	
+};	
+struct freepg {	
+  char *va;	
+  int age;	
+  struct freepg *next;	
+  struct freepg *prev;	
+};	
+
+
 // Per-process state
 struct proc {
   uint sz;                     // Size of process memory (bytes)
@@ -49,6 +88,19 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+  
+  	
+  //Swap file. must initiate with create swap file	
+  struct file *swapFile;			//page file	
+  int pagesinmem;             // No. of pages in physical memory	
+  int pagesinswapfile;        // No. of pages in swap file	
+  int totalPageFaultCount;    // Total number of page faults for this process	
+  int totalPagedOutCount;     // Total number of pages that were placed in the swap file	
+  struct freepg freepages[MAX_PSYC_PAGES];  // Pre-allocated space for the pages in physical memory linked list	
+  struct pgdesc swappedpages[MAX_PSYC_PAGES];// Pre-allocated space for the pages in swap file array	
+  struct freepg *head;        // Head of the pages in physical memory linked list	
+  struct freepg *tail;        // End of the pages in physical memory linked list
+  
 };
 
 // Process memory is laid out contiguously, low addresses first:
diff --git a/runoff b/runoff
index be362d0..26593af 100644
--- a/runoff
+++ b/runoff
@@ -14,7 +14,6 @@ pad()
 mkdir -p fmt
 rm -f fmt/*
 cp README fmt
-echo > fmt/blank
 files=`grep -v '^#' runoff.list | awk '{print $1}'`
 n=99
 for i in $files
@@ -215,9 +214,7 @@ awk '
 	# pr -t -2 t.defs | ../pr.pl -h "definitions" | pad
 	pr -t -l50 -2 refs | ../pr.pl -h "cross-references" | pad
 	# pr.pl -h "definitions" -2 t.defs | pad
-	# pr.pl -h "cross-references" -2 refs | pad
-	../pr.pl blank  # make sheet 1 start on left page
-	../pr.pl blank
+	# pr.pl -h "cross-references" -2 refs | pad 
 	for i in $files
 	do
 		../pr.pl -h "xv6/$i" $i
diff --git a/runoff.list b/runoff.list
index 2df9b81..02d1b65 100644
--- a/runoff.list
+++ b/runoff.list
@@ -7,7 +7,6 @@ x86.h
 asm.h
 mmu.h
 elf.h
-date.h
 
 # entering xv6
 entry.S
@@ -76,5 +75,3 @@ sh.c
 bootasm.S
 bootmain.c
 
-# link
-kernel.ld
diff --git a/sleeplock.c b/sleeplock.c
index e0750ea..d0e4d91 100644
--- a/sleeplock.c
+++ b/sleeplock.c
@@ -47,7 +47,7 @@ holdingsleep(struct sleeplock *lk)
   int r;
   
   acquire(&lk->lk);
-  r = lk->locked && (lk->pid == myproc()->pid);
+  r = lk->locked;
   release(&lk->lk);
   return r;
 }
diff --git a/spinlock.c b/spinlock.c
index 4020186..9120bf2 100644
--- a/spinlock.c
+++ b/spinlock.c
@@ -89,11 +89,7 @@ getcallerpcs(void *v, uint pcs[])
 int
 holding(struct spinlock *lock)
 {
-  int r;
-  pushcli();
-  r = lock->locked && lock->cpu == mycpu();
-  popcli();
-  return r;
+  return lock->locked && lock->cpu == mycpu();
 }
 
 
diff --git a/swap.h b/swap.h
new file mode 100644
index 0000000..23a8594
--- /dev/null
+++ b/swap.h
@@ -0,0 +1,108 @@
+
+// Credit: Mel Gorman
+// https://www.kernel.org/doc/gorman/html/understand/understand014.html
+// Section 11.1:  Describing the Swap Area
+
+// Implemented by Zeb Rasco <rascozeb@gmail.com>
+
+// spinlock.c
+void            acquire(struct spinlock*);
+void            getcallerpcs(void*, uint*);
+int             holding(struct spinlock*);
+void            initlock(struct spinlock*, char*);
+void            release(struct spinlock*);
+void            pushcli(void);
+void            popcli(void);
+
+
+#define SWAPFILE_FILENAME "SWAPFILE"
+//#define SWAPFILE_PAGES (((8 * 1024 * 1024) / PGSIZE) - 1)
+//#define SWAPFILE_PAGES (((1 * 1024 * 1024) / PGSIZE) - 1)
+#define SWAPFILE_PAGES 18
+#define MAX_SWAP_BADPAGES (PGIZE - 1024 - 512 - 10) / sizeof(long)
+
+/* From Linux 2.4 source code */
+#define SWP_USED	1
+#define SWP_WRITEOK	3
+#define SWAP_CLUSTER_MAX 32
+#define SWAP_MAP_MAX	0x7fff
+#define SWAP_MAP_BAD	0x8000
+
+// This would contain a prioritized swap order, but will likely be implemented as an array of one
+struct swap_list_t {
+    int head;                       // First swap area
+    int next;                       // Next swap area
+};
+
+struct swap_info_struct {
+
+    unsigned int flags;
+    //kdev_t swap_device;           // Device corresponding to the partition used for this swap area. Leave as NULL since we'll use a file
+    struct spinlock sdev_lock;      // Lock protecting the structure
+    struct file *swap_file;         // Pointer to the swapfile
+    int fd;                         // Open fd to swapfile
+    unsigned int swap_map_pages;    // Number of kalloc()'ed pages used by the swap map
+    unsigned short *swap_map;       // This is a large array with one entry for every swap entry, or page sized slot in the area.
+                                    // An entry is a reference count of the number of users of this page slot.
+                                    // The swap cache counts as one user and every PTE that has been paged out to the slot counts as a user. 
+                                    // If it is equal to SWAP_MAP_MAX, the slot is allocated permanently. If equal to SWAP_MAP_BAD, the slot will never be used;
+    unsigned int lowest_bit;        // This is the lowest possible free slot available in the swap area and is used to start 
+                                    // from when linearly scanning to reduce the search space.
+                                    // It is known that there are definitely no free slots below this mark
+    unsigned int highest_bit;       // This is the highest possible free slot available in this swap area.
+                                    // Similar to lowest_bit, there are definitely no free slots above this mark;
+    unsigned int cluster_next;      // This is the offset of the next cluster of blocks to use.
+                                    // The swap area tries to have pages allocated in cluster blocks to increase the chance related pages will be stored together;
+    unsigned int cluster_nr;        // This the number of pages left to allocate in this cluster
+    int prio;                       // Each swap area has a priority. Not needed for this version, since we only use 1
+
+    int pages;                      // Number of usable pages
+    unsigned long max;              // Total number of slots in the swap area
+    int next;                       // Unused, but would normally contain the index of the next swap area
+};
+
+// The first page of any swap area is reserved for the header below
+union swap_header {
+	struct {
+		char reserved[PGSIZE - 10];
+		char magic[10];			/* SWAP-SPACE or SWAPSPACE2 */
+	} magic;
+	struct {
+		char		        bootbits[1024];	/* Space for disklabel etc. */
+		unsigned int		version;        // This is the version of the swap area layout;
+		unsigned int		last_page;      // This is the last usable page in the area;
+		unsigned int		nr_badpages;    // The known number of bad pages that exist in the swap area are stored in this field;
+		unsigned int        padding[125];   // A disk section is usually about 512 bytes in size. 
+                                    // The three fields version, last_page and nr_badpages make up 12 bytes and the padding
+                                    // fills up the remaining 500 bytes to cover one sector;
+		unsigned int		badpages[1];    // The remainder of the page is used to store the indices of up to MAX_SWAP_BADPAGES number of bad page slots.
+                                    // This is used by mkswap, which we don't have, so we probably won't use this
+	} info;
+};
+
+// TODO: Implement these
+// #define PTE_ADDR(pte)   ((uint)(pte) & ~0xFFF)
+
+/* Encode and de-code a swap entry */   
+#define pte_to_swp_entry(pte)	((swp_entry_t) { pte })
+#define swp_entry_to_pte(x)		((pte_t) { (x).val })
+
+#define SWP_ENTRY(type, offset)		    ((swp_entry_t) { ((type) << 1) | ((offset) << 8) })
+#define SWP_OFFSET(swp_entry)           (((swp_entry).val >> 8) & 0x00FFFFFF)
+#define SWP_TYPE(swp_entry)             (((swp_entry).val >> 1) & 0x0000003F)
+
+// By having a 24-bit page offset, this allows for swapfiles up to 64GB (assuming 4096 byte PGSIZE, 64GB = 2^24 * PGSIZE)
+typedef struct {
+    unsigned long val;              // Bit 0 reserved for PTE_P flag (Page present)
+                                    // Bits 1-6 are the type (index within the swap_info array), which will always be 0 in this implementation
+                                    // But theoretically this would allow 64 seperate swap areas
+                                    // Bit 7 is reserved for PAGE_PROTNONE (Page is resident, but not accessible)
+                                    // Bits 8-31 are used are to store the offset within the swap_map from the swp_entry_t
+} swp_entry_t;
+
+/* From Linux 2.4, changed for xv6 */
+extern struct spinlock swaplock;
+#define swap_list_lock()	acquire(&swaplock)
+#define swap_list_unlock()	release(&swaplock)
+#define swap_device_lock(p)	acquire(&p->sdev_lock)
+#define swap_device_unlock(p)	release(&p->sdev_lock)
\ No newline at end of file
diff --git a/swtch.S b/swtch.S
index 63a7dcc..de612bd 100644
--- a/swtch.S
+++ b/swtch.S
@@ -11,7 +11,7 @@ swtch:
   movl 4(%esp), %eax
   movl 8(%esp), %edx
 
-  # Save old callee-saved registers
+  # Save old callee-save registers
   pushl %ebp
   pushl %ebx
   pushl %esi
@@ -21,7 +21,7 @@ swtch:
   movl %esp, (%eax)
   movl %edx, %esp
 
-  # Load new callee-saved registers
+  # Load new callee-save registers
   popl %edi
   popl %esi
   popl %ebx
diff --git a/symlink.patch b/symlink.patch
new file mode 100644
index 0000000..c7caf23
--- /dev/null
+++ b/symlink.patch
@@ -0,0 +1,151 @@
+diff -r f8a4e40ab1d6 fs.c
+--- a/fs.c	Thu Aug 30 14:32:06 2007 -0400
++++ b/fs.c	Thu Aug 30 14:29:02 2007 -0400
+@@ -577,12 +577,18 @@ skipelem(char *path, char *name)
+ // If parent != 0, return the inode for the parent and copy the final
+ // path element into name, which must have room for DIRSIZ bytes.
+ static struct inode*
+-_namei(char *path, int parent, char *name)
++_namei(struct inode *root, char *path, int parent, char *name, int depth)
+ {
+   struct inode *ip, *next;
++  char buf[100], tname[DIRSIZ];
++
++  if(depth > 5)
++    return 0;
+ 
+   if(*path == '/')
+     ip = iget(ROOTDEV, 1);
++  else if(root)
++    ip = idup(root);
+   else
+     ip = idup(cp->cwd);
+ 
+@@ -598,10 +604,24 @@ _namei(char *path, int parent, char *nam
+       return ip;
+     }
+     if((next = dirlookup(ip, name, 0)) == 0){
++      cprintf("did not find %s\n", name);
+       iunlockput(ip);
+       return 0;
+     }
+-    iunlockput(ip);
++    iunlock(ip);
++    ilock(next);
++    if(next->type == T_SYMLINK){
++      if(next->size >= sizeof(buf) || readi(next, buf, 0, next->size) != next->size){
++        iunlockput(next);
++        iput(ip);
++        return 0;
++      }
++      buf[next->size] = 0;
++      iunlockput(next);
++      next = _namei(ip, buf, 0, tname, depth+1);
++    }else
++      iunlock(next);
++    iput(ip);
+     ip = next;
+   }
+   if(parent){
+@@ -615,11 +635,11 @@ namei(char *path)
+ namei(char *path)
+ {
+   char name[DIRSIZ];
+-  return _namei(path, 0, name);
++  return _namei(0, path, 0, name, 0);
+ }
+ 
+ struct inode*
+ nameiparent(char *path, char *name)
+ {
+-  return _namei(path, 1, name);
+-}
++  return _namei(0, path, 1, name, 0);
++}
+diff -r f8a4e40ab1d6 fs.h
+--- a/fs.h	Thu Aug 30 14:32:06 2007 -0400
++++ b/fs.h	Thu Aug 30 13:05:43 2007 -0400
+@@ -33,6 +33,7 @@ struct dinode {
+ #define T_DIR  1   // Directory
+ #define T_FILE 2   // File
+ #define T_DEV  3   // Special device
++#define T_SYMLINK 4  // Symlink
+ 
+ // Inodes per block.
+ #define IPB           (BSIZE / sizeof(struct dinode))
+diff -r f8a4e40ab1d6 syscall.c
+--- a/syscall.c	Thu Aug 30 14:32:06 2007 -0400
++++ b/syscall.c	Thu Aug 30 13:05:29 2007 -0400
+@@ -96,6 +96,7 @@ extern int sys_unlink(void);
+ extern int sys_unlink(void);
+ extern int sys_wait(void);
+ extern int sys_write(void);
++extern int sys_symlink(void);
+ 
+ static int (*syscalls[])(void) = {
+ [SYS_chdir]   sys_chdir,
+@@ -118,6 +119,7 @@ static int (*syscalls[])(void) = {
+ [SYS_unlink]  sys_unlink,
+ [SYS_wait]    sys_wait,
+ [SYS_write]   sys_write,
++[SYS_symlink]	sys_symlink,
+ };
+ 
+ void
+diff -r f8a4e40ab1d6 syscall.h
+--- a/syscall.h	Thu Aug 30 14:32:06 2007 -0400
++++ b/syscall.h	Thu Aug 30 13:02:48 2007 -0400
+@@ -19,3 +19,4 @@
+ #define SYS_getpid 18
+ #define SYS_sbrk   19
+ #define SYS_sleep  20
++#define SYS_symlink 21
+diff -r f8a4e40ab1d6 sysfile.c
+--- a/sysfile.c	Thu Aug 30 14:32:06 2007 -0400
++++ b/sysfile.c	Thu Aug 30 13:10:31 2007 -0400
+@@ -257,6 +257,21 @@ create(char *path, int canexist, short t
+ }
+ 
+ int
++sys_symlink(void)
++{
++  char *old, *new;
++  struct inode *ip;
++  
++  if(argstr(0, &old) < 0 || argstr(1, &new) < 0)
++    return -1;
++  if((ip = create(new, 0, T_SYMLINK, 0, 0)) == 0)
++    return -1;
++  writei(ip, old, 0, strlen(old));
++  iunlockput(ip);
++  return 0;
++}
++
++int
+ sys_open(void)
+ {
+   char *path;
+@@ -393,3 +408,4 @@ sys_pipe(void)
+   fd[1] = fd1;
+   return 0;
+ }
++
+diff -r f8a4e40ab1d6 user.h
+--- a/user.h	Thu Aug 30 14:32:06 2007 -0400
++++ b/user.h	Thu Aug 30 13:02:34 2007 -0400
+@@ -21,6 +21,7 @@ int getpid();
+ int getpid();
+ char* sbrk(int);
+ int sleep(int);
++int symlink(int);
+ 
+ // ulib.c
+ int stat(char*, struct stat*);
+diff -r f8a4e40ab1d6 usys.S
+--- a/usys.S	Thu Aug 30 14:32:06 2007 -0400
++++ b/usys.S	Thu Aug 30 13:05:54 2007 -0400
+@@ -28,3 +28,4 @@ STUB(getpid)
+ STUB(getpid)
+ STUB(sbrk)
+ STUB(sleep)
++STUB(symlink)
diff --git a/syscall.c b/syscall.c
index ee85261..6961ca6 100644
--- a/syscall.c
+++ b/syscall.c
@@ -60,7 +60,7 @@ argptr(int n, char **pp, int size)
 {
   int i;
   struct proc *curproc = myproc();
- 
+
   if(argint(n, &i) < 0)
     return -1;
   if(size < 0 || (uint)i >= curproc->sz || (uint)i+size > curproc->sz)
@@ -103,6 +103,8 @@ extern int sys_unlink(void);
 extern int sys_wait(void);
 extern int sys_write(void);
 extern int sys_uptime(void);
+extern int sys_bstat(void);
+extern int sys_swap(void);
 
 static int (*syscalls[])(void) = {
 [SYS_fork]    sys_fork,
@@ -126,6 +128,8 @@ static int (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_bstat]   sys_bstat,
+[SYS_swap]    sys_swap,
 };
 
 void
diff --git a/syscall.h b/syscall.h
index bc5f356..b621abc 100644
--- a/syscall.h
+++ b/syscall.h
@@ -20,3 +20,5 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_bstat  22
+#define SYS_swap   23
diff --git a/sysfile.c b/sysfile.c
index bfe61b7..4864a33 100644
--- a/sysfile.c
+++ b/sysfile.c
@@ -15,6 +15,36 @@
 #include "sleeplock.h"
 #include "file.h"
 #include "fcntl.h"
+#include "paging.h"
+#include "memlayout.h"
+
+extern int numallocblocks;
+
+// Return the address of the PTE in page table pgdir
+// that corresponds to virtual address va.  If alloc!=0,
+// create any required page table pages.
+static pte_t *
+walkpgdir(pde_t *pgdir, const void *va, int alloc)
+{
+  pde_t *pde;
+  pte_t *pgtab;
+
+  pde = &pgdir[PDX(va)];
+  if(*pde & PTE_P){
+    pgtab = (pte_t*)P2V(PTE_ADDR(*pde));
+  } else {
+    if(!alloc || (pgtab = (pte_t*)kalloc()) == 0)
+      return 0;
+    // Make sure all those PTE_P bits are zero.
+    memset(pgtab, 0, PGSIZE);
+    // The permissions here are overly generous, but they can
+    // be further restricted by the permissions in the page table
+    // entries, if necessary.
+    *pde = V2P(pgtab) | PTE_P | PTE_W | PTE_U;
+  }
+  return &pgtab[PTX(va)];
+}
+
 
 // Fetch the nth word-sized system call argument as a file descriptor
 // and return both the descriptor and the corresponding struct file.
@@ -165,7 +195,7 @@ bad:
 }
 
 // Is the directory dp empty except for "." and ".." ?
-static int
+int
 isdirempty(struct inode *dp)
 {
   int off;
@@ -238,9 +268,10 @@ bad:
   return -1;
 }
 
-static struct inode*
+struct inode*
 create(char *path, short type, short major, short minor)
 {
+  uint off;
   struct inode *ip, *dp;
   char name[DIRSIZ];
 
@@ -248,7 +279,7 @@ create(char *path, short type, short major, short minor)
     return 0;
   ilock(dp);
 
-  if((ip = dirlookup(dp, name, 0)) != 0){
+  if((ip = dirlookup(dp, name, &off)) != 0){
     iunlockput(dp);
     ilock(ip);
     if(type == T_FILE && ip->type == T_FILE)
@@ -374,7 +405,7 @@ sys_chdir(void)
   char *path;
   struct inode *ip;
   struct proc *curproc = myproc();
-  
+
   begin_op();
   if(argstr(0, &path) < 0 || (ip = namei(path)) == 0){
     end_op();
@@ -442,3 +473,34 @@ sys_pipe(void)
   fd[1] = fd1;
   return 0;
 }
+
+/* returns the number of swapped pages
+ */
+int
+sys_bstat(void)
+{
+  //************xv7************
+	return numallocblocks;
+}
+
+/* swap system call handler.
+ */
+
+ //*************xv7************
+int
+sys_swap(void)
+{
+  uint addr;
+
+  if(argint(0, (int*)&addr) < 0)
+    return -1;
+  // swap addr
+  struct proc *currentProcess=myproc();
+  pde_t *pgdir=currentProcess->pgdir;
+  pte_t *pte=walkpgdir(pgdir,(char*)addr,1);
+  if(*pte & PTE_P){
+    swap_page_from_pte(pte);
+  }
+
+  return 0;
+}
diff --git a/trap.c b/trap.c
index 41c66eb..1437ecf 100644
--- a/trap.c
+++ b/trap.c
@@ -7,6 +7,7 @@
 #include "x86.h"
 #include "traps.h"
 #include "spinlock.h"
+#include "paging.h"
 
 // Interrupt descriptor table (shared by all CPUs).
 struct gatedesc idt[256];
@@ -47,6 +48,9 @@ trap(struct trapframe *tf)
   }
 
   switch(tf->trapno){
+  case T_PGFLT:
+  	handle_pgfault();
+  	break;
   case T_IRQ0 + IRQ_TIMER:
     if(cpuid() == 0){
       acquire(&tickslock);
diff --git a/ulib.c b/ulib.c
index 8e1e1a2..51a9e74 100644
--- a/ulib.c
+++ b/ulib.c
@@ -5,7 +5,7 @@
 #include "x86.h"
 
 char*
-strcpy(char *s, const char *t)
+strcpy(char *s, char *t)
 {
   char *os;
 
@@ -24,7 +24,7 @@ strcmp(const char *p, const char *q)
 }
 
 uint
-strlen(const char *s)
+strlen(char *s)
 {
   int n;
 
@@ -68,7 +68,7 @@ gets(char *buf, int max)
 }
 
 int
-stat(const char *n, struct stat *st)
+stat(char *n, struct stat *st)
 {
   int fd;
   int r;
@@ -93,10 +93,9 @@ atoi(const char *s)
 }
 
 void*
-memmove(void *vdst, const void *vsrc, int n)
+memmove(void *vdst, void *vsrc, int n)
 {
-  char *dst;
-  const char *src;
+  char *dst, *src;
 
   dst = vdst;
   src = vsrc;
diff --git a/user.h b/user.h
index 4f99c52..3d95b60 100644
--- a/user.h
+++ b/user.h
@@ -6,33 +6,35 @@ int fork(void);
 int exit(void) __attribute__((noreturn));
 int wait(void);
 int pipe(int*);
-int write(int, const void*, int);
+int write(int, void*, int);
 int read(int, void*, int);
 int close(int);
 int kill(int);
 int exec(char*, char**);
-int open(const char*, int);
-int mknod(const char*, short, short);
-int unlink(const char*);
+int open(char*, int);
+int mknod(char*, short, short);
+int unlink(char*);
 int fstat(int fd, struct stat*);
-int link(const char*, const char*);
-int mkdir(const char*);
-int chdir(const char*);
+int link(char*, char*);
+int mkdir(char*);
+int chdir(char*);
 int dup(int);
 int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int bstat(void);
+int swap(void*);
 
 // ulib.c
-int stat(const char*, struct stat*);
-char* strcpy(char*, const char*);
-void *memmove(void*, const void*, int);
+int stat(char*, struct stat*);
+char* strcpy(char*, char*);
+void *memmove(void*, void*, int);
 char* strchr(const char*, char c);
 int strcmp(const char*, const char*);
-void printf(int, const char*, ...);
+void printf(int, char*, ...);
 char* gets(char*, int max);
-uint strlen(const char*);
+uint strlen(char*);
 void* memset(void*, int, uint);
 void* malloc(uint);
 void free(void*);
diff --git a/usys.S b/usys.S
index 8bfd8a1..241bd38 100644
--- a/usys.S
+++ b/usys.S
@@ -29,3 +29,5 @@ SYSCALL(getpid)
 SYSCALL(sbrk)
 SYSCALL(sleep)
 SYSCALL(uptime)
+SYSCALL(bstat)
+SYSCALL(swap)
diff --git a/vm.c b/vm.c
index 7134cff..40af28d 100644
--- a/vm.c
+++ b/vm.c
@@ -6,6 +6,8 @@
 #include "mmu.h"
 #include "proc.h"
 #include "elf.h"
+#include "paging.h"
+#include "fs.h"
 
 extern char data[];  // defined by kernel.ld
 pde_t *kpgdir;  // for use in scheduler()
@@ -69,7 +71,7 @@ mappages(pde_t *pgdir, void *va, uint size, uint pa, int perm)
     if((pte = walkpgdir(pgdir, a, 1)) == 0)
       return -1;
     if(*pte & PTE_P)
-      panic("remap");
+      panic("remap in mappages in vm.c");
     *pte = pa | perm | PTE_P;
     if(a == last)
       break;
@@ -230,16 +232,17 @@ allocuvm(pde_t *pgdir, uint oldsz, uint newsz)
     return oldsz;
 
   a = PGROUNDUP(oldsz);
+
   for(; a < newsz; a += PGSIZE){
     mem = kalloc();
     if(mem == 0){
-      cprintf("allocuvm out of memory\n");
+      //cprintf("allocuvm out of memory\n");
       deallocuvm(pgdir, newsz, oldsz);
       return 0;
     }
     memset(mem, 0, PGSIZE);
     if(mappages(pgdir, (char*)a, PGSIZE, V2P(mem), PTE_W|PTE_U) < 0){
-      cprintf("allocuvm out of memory (2)\n");
+      //cprintf("allocuvm out of memory (2)\n");
       deallocuvm(pgdir, newsz, oldsz);
       kfree(mem);
       return 0;
@@ -252,6 +255,7 @@ allocuvm(pde_t *pgdir, uint oldsz, uint newsz)
 // newsz.  oldsz and newsz need not be page-aligned, nor does newsz
 // need to be less than oldsz.  oldsz can be larger than the actual
 // process size.  Returns the new process size.
+// If the page was swapped free the corresponding disk block.
 int
 deallocuvm(pde_t *pgdir, uint oldsz, uint newsz)
 {
@@ -264,8 +268,15 @@ deallocuvm(pde_t *pgdir, uint oldsz, uint newsz)
   a = PGROUNDUP(newsz);
   for(; a  < oldsz; a += PGSIZE){
     pte = walkpgdir(pgdir, (char*)a, 0);
+
     if(!pte)
       a = PGADDR(PDX(a) + 1, 0, 0) - PGSIZE;
+
+    else if(*pte & PTE_SWAPPED){
+        uint block_id= (*pte)>>12;
+        bfree_page(ROOTDEV,block_id);
+      }
+
     else if((*pte & PTE_P) != 0){
       pa = PTE_ADDR(*pte);
       if(pa == 0)
@@ -274,6 +285,7 @@ deallocuvm(pde_t *pgdir, uint oldsz, uint newsz)
       kfree(v);
       *pte = 0;
     }
+
   }
   return newsz;
 }
@@ -297,6 +309,78 @@ freevm(pde_t *pgdir)
   kfree((char*)pgdir);
 }
 
+// Select a page-table entry which is mapped
+// but not accessed. Notice that the user memory
+// is mapped between 0...KERNBASE.
+
+/* ********xv7*************
+i) in the kmem.freelist, find a page whose access bit is not setting
+ii) if (i) is unable to find any such page, randomly reset access bit
+    of 10% of the allocated pages and call select_a_victim() again
+*/
+
+pte_t*
+select_a_victim(pde_t *pgdir)
+{
+  pte_t *pte;
+  for(long i=4096; i<KERNBASE;i+=PGSIZE){    //for all pages in the user virtual space
+  
+    if((pte=walkpgdir(pgdir,(char*)i,0))!= 0) //if mapping exists (0 as 3rd argument as we dont want to create mapping if does not exists)
+		  {    
+
+           if(*pte & PTE_P) //if not dirty, or (present and access bit not set)  --- conditions needs to be checked
+           {   if(*pte & ~PTE_A)             //access bit is NOT set.
+               {
+                 return pte;
+               }
+           }
+      }
+      else{
+
+        cprintf("walkpgdir failed \n ");
+      }
+	}
+
+  return 0;
+}
+
+// Clear access bit of a random pte.
+void
+clearaccessbit(pde_t *pgdir)
+{ pte_t *pte;
+  int count=0;
+  for(long i=4096;i<KERNBASE;i+=PGSIZE){
+      if((pte=walkpgdir(pgdir,(char*)i,0))!= 0){
+        cprintf("walkpkgdir mei");
+        if((*pte & PTE_P) & (*pte & PTE_A)){
+            *pte &= ~PTE_A;
+            count=count+1;
+            if(count<103){
+              cprintf("103 se kam hai");
+            }
+            else{
+              cprintf("103 se zyaada ho gya");
+            }
+        }
+    }
+  
+    if(count==103)   //10% of the 1024 pages cleared
+      return;
+  }
+}
+
+// return the disk block-id, if the virtual address
+// was swapped, -1 otherwise.
+int
+getswappedblk(pde_t *pgdir, uint va)
+{
+  //***************xv7**************
+  pte_t *pte= walkpgdir(pgdir,(char*)va,0);
+  //first 20 bits contain block-id, extract them from *pte
+  int block_id= (*pte)>>12;
+  return block_id;
+}
+
 // Clear PTE_U on a page. Used to create an inaccessible
 // page beneath the user stack.
 void
@@ -319,24 +403,51 @@ copyuvm(pde_t *pgdir, uint sz)
   pte_t *pte;
   uint pa, i, flags;
   char *mem;
-
   if((d = setupkvm()) == 0)
     return 0;
+  // cprintf("process size is: %d",sz);
   for(i = 0; i < sz; i += PGSIZE){
+    // cprintf("i is :%d",i);
     if((pte = walkpgdir(pgdir, (void *) i, 0)) == 0)
       panic("copyuvm: pte should exist");
-    if(!(*pte & PTE_P))
-      panic("copyuvm: page not present");
+
+    if(*pte & PTE_SWAPPED){
+    //  *********************xv7******************
+    //cprintf("page was swapped\n");
+      if((mem = kalloc()) == 0)
+      {
+        swap_page(pgdir);
+        mem=kalloc();
+      }
+      int blockid=getswappedblk(pgdir,i);      //disk id where the page was swapped
+      read_page_from_disk(ROOTDEV,mem,blockid);
+
+      *pte=V2P(mem) | PTE_W | PTE_U | PTE_P;
+      *pte &= ~PTE_SWAPPED;
+      lcr3(V2P(pgdir));
+
+      bfree_page(ROOTDEV,blockid);
+
+      //panic("copyuvm: page not present");
+    }
+    //  cprintf("page was not swapped\n");
     pa = PTE_ADDR(*pte);
     flags = PTE_FLAGS(*pte);
     if((mem = kalloc()) == 0)
-      goto bad;
+    {
+    //  goto bad;
+    //swap a page to disk and kalloc
+      swap_page(pgdir);
+      mem=kalloc();
+      if(mem==0)
+        cprintf("unable to get memory in copyuvm");
+    }
+
     memmove(mem, (char*)P2V(pa), PGSIZE);
-    if(mappages(d, (void*)i, PGSIZE, V2P(mem), flags) < 0) {
-      kfree(mem);
+    if(mappages(d, (void*)i, PGSIZE, V2P(mem), flags) < 0)
       goto bad;
-    }
-  }
+}
+  //cprintf("exiting from copyuvm");
   return d;
 
 bad:
@@ -359,6 +470,14 @@ uva2ka(pde_t *pgdir, char *uva)
   return (char*)P2V(PTE_ADDR(*pte));
 }
 
+// returns the page table entry corresponding
+// to a virtual address.
+pte_t*
+uva2pte(pde_t *pgdir, uint uva)
+{
+  return walkpgdir(pgdir, (void*)uva, 0);
+}
+
 // Copy len bytes from p to user address va in page table pgdir.
 // Most useful when pgdir is not the current page table.
 // uva2ka ensures this only works for PTE_U pages.
@@ -391,4 +510,3 @@ copyout(pde_t *pgdir, uint va, void *p, uint len)
 // Blank page.
 //PAGEBREAK!
 // Blank page.
-
